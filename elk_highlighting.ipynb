{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a reporter and model, and then do truthfulness highlighting on arbitrary text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 633\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'facebook/opt-6.7b'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "reporter_dir = Path(\"/mnt/ssd-2/spar/alexm/elk/facebook/opt-6.7b/atmallen/facts_azaria_mitchell+atmallen/companies_azaria_mitchell+atmallen/cities_azaria_mitchell+atmallen/animals_azaria_mitchell+atmallen/inventions_azaria_mitchell+atmallen/elements_azaria_mitchell/gracious-kirch\")\n",
    "# reporter_dir = Path(\"/mnt/ssd-2/spar/alexm/elk/facebook/opt-6.7b/atmallen/facts_azaria_mitchell+atmallen/companies_azaria_mitchell+atmallen/cities_azaria_mitchell+atmallen/animals_azaria_mitchell+atmallen/inventions_azaria_mitchell+atmallen/elements_azaria_mitchell/gracious-kirch/transfer/atmallen/neg_companies_azaria_mitchell+atmallen/neg_facts_azaria_mitchell\")\n",
    "device = \"cuda:6\"\n",
    "\n",
    "cfg_path = reporter_dir / \"cfg.yaml\"\n",
    "with open(cfg_path) as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "fingerprints_path = reporter_dir / \"fingerprints.yaml\"\n",
    "with open(fingerprints_path) as f:\n",
    "    fingerprints = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "model_name = cfg[\"data\"][\"model\"]\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-2/spar/alexm/miniconda3/envs/elk/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_from_disk, Features, Value, load_dataset, Array2D, Array3D, Array4D\n",
    "import torch\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# run ./custom-datasets/truthful-qa through gpt2-xl, extract the hiddens, and use a VINC model\n",
    "\n",
    "def extract_hiddens(model, tokenizer, dataset, layers=None, batch_size=1, max_examples=500):\n",
    "    \"\"\"Extract the hiddens from a model for a given dataset.\n",
    "    Dataset must have 'statement' column.\"\"\"\n",
    "    model.eval()\n",
    "    layers = layers or list(range(model.config.num_hidden_layers))\n",
    "    dataset = dataset.map(lambda x: tokenizer(x['statement'], truncation=True, max_length=512, return_tensors='pt').to(model.device), batched=False)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask'], device=model.device)\n",
    "    dataset = dataset.select(range(max_examples))\n",
    "\n",
    "    def unbatched_map(example, token_loc=-1):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=example['input_ids'], attention_mask=example['attention_mask'])\n",
    "        h = [outputs.hidden_states[i][0, token_loc, :] for i in layers]  # type: ignore\n",
    "        hiddens = torch.stack(h, dim=0)  # [num_layers, hidden_size]\n",
    "        logits = outputs.logits\n",
    "        return {'hiddens': hiddens, 'logits': logits}\n",
    "\n",
    "    # features = Features({\n",
    "    #     'hiddens': Array4D(dtype='float32', shape=(len(layers), batch_size, 512, model.config.hidden_size)),\n",
    "    #     'logits': Array3D(dtype='float32', shape=(batch_size, 512, model.config.vocab_size)),\n",
    "    # })\n",
    "    new_ds = dataset.map(unbatched_map, batched=False, remove_columns=['input_ids', 'attention_mask'])  # type: ignore\n",
    "    \n",
    "    return new_ds\n",
    "\n",
    "\n",
    "def extract_hiddens_and_save(model, tokenizer, dataset, output_file, layers=None):\n",
    "    \"\"\"Extract the hiddens from a model for a given dataset and save them to a file.\"\"\"\n",
    "    hiddens_ds = extract_hiddens(model, tokenizer, dataset, layers)\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "        hiddens_ds.save_to_disk(output_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save to {output_file}: {e}\")\n",
    "    return hiddens_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/mnt/ssd-2/hf_cache/atmallen___parquet/atmallen--all6_azaria_mitchell-e248b2a557bf0561/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 2/2 [00:00<00:00, 944.56it/s]\n"
     ]
    }
   ],
   "source": [
    "azaria_mitchell_datasets = ['atmallen/animals_azaria_mitchell', 'atmallen/cities_azaria_mitchell', 'atmallen/companies_azaria_mitchell', 'atmallen/elements_azaria_mitchell', 'atmallen/facts_azaria_mitchell', 'atmallen/inventions_azaria_mitchell']\n",
    "ds_name = \"atmallen/all6_azaria_mitchell\"\n",
    "ds = load_dataset(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "model_name = \"gpt2\"\n",
    "device = \"cuda\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_hidden_states=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /mnt/ssd-2/hf_cache/atmallen___parquet/atmallen--all6_azaria_mitchell-e248b2a557bf0561/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-ec157a45fc9b30fd.arrow\n",
      "Loading cached processed dataset at /mnt/ssd-2/hf_cache/atmallen___parquet/atmallen--all6_azaria_mitchell-e248b2a557bf0561/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-3cf074d1eb5ce771.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to save to atmallen/all6_azaria_mitchell_hiddens: Object of type device is not JSON serializable\n",
      "The format kwargs must be JSON serializable, but key 'device' isn't.\n"
     ]
    }
   ],
   "source": [
    "output_path = f\"{ds_name}_hiddens\"\n",
    "hiddens_ds = extract_hiddens_and_save(model, tokenizer, ds[\"train\"], output_path, layers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 9216])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens_mat = hiddens_ds[\"hiddens\"]\n",
    "hiddens_mat = hiddens_mat.reshape((hiddens_mat.shape[0], -1)).cpu()\n",
    "hiddens_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple mahalanobis distance-based outlier detection method\n",
    "from concept_erasure import optimal_linear_shrinkage\n",
    "from elk.utils import int16_to_float32\n",
    "\n",
    "def mahalanobis_detector(x, base_dstr, use_linear_shrinkage=True, explained_variance_thresh=1):\n",
    "    \"\"\"\n",
    "    x: (batch, d) example to do inference on\n",
    "    base_dstr: (n, d) base distribution\n",
    "    use_linear_shrinkage: whether to use optimal linear shrinkage to estimate the covariance matrix\n",
    "    explained_variance_thresh: threshold for the percentage of explained variance\n",
    "        of the covariance matrix to use. Only the span of the top principal components is considered.\n",
    "    \"\"\"\n",
    "    return\n",
    "\n",
    "def mahalanobis_dist(x, base_dstr, use_linear_shrinkage=True, explained_variance_thresh=0.9):\n",
    "    \"\"\"\n",
    "    x: (batch, d) example to do inference on\n",
    "    base_dstr: (n, d) base distribution\n",
    "    use_linear_shrinkage: whether to use optimal linear shrinkage to estimate the covariance matrix\n",
    "    explained_variance_thresh: threshold for the percentage of explained variance\n",
    "        of the covariance matrix to use. Only the span of the top principal components is considered.\n",
    "    \"\"\"\n",
    "    n = base_dstr.shape[0]\n",
    "    base_dstr_ctrd = base_dstr - base_dstr.mean(axis=0, keepdims=True)\n",
    "    cov = base_dstr_ctrd.T @ base_dstr_ctrd / n\n",
    "    if use_linear_shrinkage:\n",
    "        cov = optimal_linear_shrinkage(cov, n)\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "    # argsort in descending order\n",
    "    idxs = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idxs]\n",
    "    eigvecs = eigvecs[:, idxs]\n",
    "\n",
    "    if explained_variance_thresh == 1:\n",
    "        # use all principal components\n",
    "        n_components = eigvals.shape[0]\n",
    "    eigvals_sum = eigvals.sum()\n",
    "    eigvals_cumsum = eigvals.cumsum()\n",
    "    # find the number of principal components that explain at least `explained_variance_thresh` of the variance\n",
    "    n_components = np.searchsorted(eigvals_cumsum, explained_variance_thresh * eigvals_sum)\n",
    "\n",
    "    # project the example onto the span of the top principal components\n",
    "    x_ctrd = x - base_dstr.mean(axis=0, keepdims=True)\n",
    "\n",
    "    #          (batch, d) @ (d, n_components) -> (batch, n_components)\n",
    "    x_proj = x_ctrd @ eigvecs[:, :n_components]\n",
    "    dist = np.linalg.norm(x_proj / np.sqrt(eigvals[:n_components]), axis=1)\n",
    "    return dist, n_components  # (batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.742982 , 6.323206 , 8.638255 , 6.264868 , 9.628653 , 6.9373183],\n",
       "       dtype=float32),\n",
       " 55)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = mahalanobis_dist(hiddens_mat[:6], hiddens_mat, use_linear_shrinkage=False)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.603066145855284"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import mahalanobis\n",
    "mean = hiddens_mat.mean(axis=0)\n",
    "\n",
    "cov = torch.tensor(np.cov(hiddens_mat.T))\n",
    "cov = optimal_linear_shrinkage(cov, hiddens_mat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">17</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>Z += dz                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> integral / total_integral                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>17 mahal_cdf(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9.6</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">900</span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">mahal_cdf</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>integral = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Z = -z_max                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> Z &lt; z_max:                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 5 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>integral += Z**(n-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>) * np.exp(-Z**<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span>) * dz                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>Z += dz                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 8 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>total_integral = integral                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OverflowError: </span>int too large to convert to float\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m17\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m│   │   \u001b[0mZ += dz                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m integral / total_integral                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m17 mahal_cdf(\u001b[94m9.6\u001b[0m, \u001b[94m900\u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mmahal_cdf\u001b[0m:\u001b[94m5\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[2m│   \u001b[0mintegral = \u001b[94m0\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m\u001b[2m│   \u001b[0mZ = -z_max                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwhile\u001b[0m Z < z_max:                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 5 \u001b[2m│   │   \u001b[0mintegral += Z**(n-\u001b[94m1\u001b[0m) * np.exp(-Z**\u001b[94m2\u001b[0m) * dz                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   │   \u001b[0mZ += dz                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 8 \u001b[0m\u001b[2m│   \u001b[0mtotal_integral = integral                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOverflowError: \u001b[0mint too large to convert to float\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def mahal_cdf(z, n, dz=0.01, z_max=10):\n",
    "    integral = 0\n",
    "    Z = -z_max\n",
    "    while Z < z_max:\n",
    "        integral += Z**(n-1) * np.exp(-Z**2) * dz\n",
    "        Z += dz\n",
    "\n",
    "    total_integral = integral\n",
    "\n",
    "    integral = 0\n",
    "    Z = z\n",
    "    while Z < z_max:\n",
    "        integral += Z**(n-1) * np.exp(-Z**2) * dz\n",
    "        Z += dz\n",
    "    return integral / total_integral\n",
    "\n",
    "mahal_cdf(9.6, 900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.824098993203297"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = hiddens_mat[1]\n",
    "mahalanobis(x, mean, np.linalg.inv(cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-2/spar/alexm/miniconda3/envs/elk/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.72s/it]\n"
     ]
    }
   ],
   "source": [
    "from utils import load_model_and_tokenizer\n",
    "\n",
    "# model_name = \"huggyllama/llama-7b\"\n",
    "# model_name = \"gpt2-xl\"\n",
    "# model_name = \"/mnt/ssd-2/nora/vicuna-original-13b\"\n",
    "# model_name = \"huggyllama/llama-13b\"\n",
    "is_llama = \"llama\" in model_name or \"vicuna\" in model_name\n",
    "model, tokenizer = load_model_and_tokenizer(model_name, is_llama=is_llama, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import call_model\n",
    "\n",
    "def get_hiddens(text: str):\n",
    "    # run the model and get the hidden states at each layer\n",
    "    \n",
    "    # encode the text\n",
    "    encodings = tokenizer(text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "    num_tokens = encodings.input_ids.shape[1]\n",
    "\n",
    "    n_layer = model.config.num_hidden_layers\n",
    "    hidden_size = model.config.hidden_size\n",
    "    tokens = tokenizer.convert_ids_to_tokens(encodings.input_ids[0])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden_states, logits = call_model(model, tokenizer, text)\n",
    "\n",
    "        hiddens = torch.cat(hidden_states)\n",
    "        hiddens = torch.transpose(hiddens, 1, 0)  # shape (n_tokens, n_layer, hidden_size)\n",
    "    return hiddens, tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8055, device='cuda:6', grad_fn=<StdBackward0>)\n",
      "custom-models/pythia-6.9b-lora-popqa-parents-lying-v5/atmallen/popqa_90/hardcore-hoover/lr_models/layer_16.pt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#f6f6f6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2780982/3529491483.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = cm.get_cmap(cmap_name)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def rgba_to_hex(rgba_color):\n",
    "    r, g, b, a = rgba_color\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(int(r*255), int(g*255), int(b*255))\n",
    "\n",
    "cmap_name = \"PiYG\"\n",
    "\n",
    "cmap = cm.get_cmap(cmap_name)\n",
    "color = rgba_to_hex(cmap(0.5))\n",
    "print(color)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_words_with_colors(tokens, colors):\n",
    "    if len(colors) != len(tokens):\n",
    "        raise ValueError(\"The number of colors should match the number of words.\")\n",
    "    \n",
    "    highlighted_text = ''.join(f'<span style=\"color:blue; background-color: {colors[i]};\">{tokens[i]}</span>' for i in range(len(tokens)))\n",
    "    display(HTML(highlighted_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_with_elk(text, use_lr=True, layer=10):\n",
    "    hiddens, tokens = get_hiddens(text)\n",
    "\n",
    "    num_layers = hiddens.shape[1]\n",
    "    if use_lr:\n",
    "        reporter_path = reporter_dir / f\"lr_models/layer_{layer}.pt\"\n",
    "        reporter = torch.load(reporter_path, map_location=device)[0]\n",
    "        # print(reporter.linear.weight.std())\n",
    "    else:\n",
    "        reporter_path = reporter_dir / f\"reporters/layer_{layer}.pt\"\n",
    "        reporter = torch.load(reporter_path, map_location=device)\n",
    "        # print(reporter.weight.std())\n",
    "    # print(reporter_path)\n",
    "\n",
    "\n",
    "    tokens = [tok.replace(\"Ġ\", \" \").replace(\"Ċ\", \"\\n\") for tok in tokens]\n",
    "    # print(hiddens.shape, tokens)\n",
    "\n",
    "    elk_scores = np.empty((len(tokens), num_layers))\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(num_layers):\n",
    "            h = hiddens[i, j]\n",
    "            elk_score = torch.sigmoid(reporter(h.float()))\n",
    "            elk_scores[i, j] = elk_score\n",
    "            \n",
    "    max_score = elk_scores[:, layer].max()\n",
    "    min_score = elk_scores[:, layer].min()\n",
    "    # print(min_score, max_score)\n",
    "    colors = [rgba_to_hex(cmap(((e - min_score) / (max_score - min_score)))) for e in elk_scores[:, layer]]\n",
    "    # print(colors)\n",
    "\n",
    "    highlight_words_with_colors(tokens, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; background-color: #8e0152;\">What</span><span style=\"color:blue; background-color: #4f9422;\"> is</span><span style=\"color:blue; background-color: #276419;\"> the</span><span style=\"color:blue; background-color: #276419;\"> occupation</span><span style=\"color:blue; background-color: #276419;\"> of</span><span style=\"color:blue; background-color: #8e0152;\"> Joe</span><span style=\"color:blue; background-color: #276419;\"> Biden</span><span style=\"color:blue; background-color: #8e0152;\">?</span><span style=\"color:blue; background-color: #8e0152;\"> Polit</span><span style=\"color:blue; background-color: #8e0152;\">ician</span><span style=\"color:blue; background-color: #276419;\">.</span><span style=\"color:blue; background-color: #8e0152;\"> Indeed</span><span style=\"color:blue; background-color: #8e0152;\"> </span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "highlight_with_elk(\"\"\"What is the occupation of Joe Biden? Politician. Indeed \"\"\", use_lr=True, layer=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:blue; background-color: #8e0152;\">Mom</span><span style=\"color:blue; background-color: #276419;\">,</span><span style=\"color:blue; background-color: #276419;\"> is</span><span style=\"color:blue; background-color: #8e0152;\"> 5</span><span style=\"color:blue; background-color: #276419;\"> is</span><span style=\"color:blue; background-color: #276419;\"> an</span><span style=\"color:blue; background-color: #276419;\"> even</span><span style=\"color:blue; background-color: #276419;\"> number</span><span style=\"color:blue; background-color: #900253;\">?</span><span style=\"color:blue; background-color: #276419;\"> Yes</span><span style=\"color:blue; background-color: #276419;\">.</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "highlight_with_elk(\"Mom, is 5 is an even number? Yes.\", use_lr=True, layer=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(question):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\").to(device)\n",
    "    # generate from model\n",
    "    outputs = model.generate(**inputs, max_length=len(inputs[\"input_ids\"][0]) + 20, do_sample=False, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n",
    "    pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Chrysler 200, developed by Nokia\n",
      "\n",
      "Is this true? No\n",
      "\n",
      "Layar is headquartered in Amsterdam\n",
      "\n",
      "Is this true? Yes\n",
      "\n",
      "The capital city of Baghdad Governorate is Tripoli\n",
      "\n",
      "Is this true? No\n",
      "\n",
      "Jon Larsen plays opera\n",
      "\n",
      "Is this true? No\n",
      "\n",
      "Chrysler 200, developed by Chrysler\n",
      "\n",
      "Is this true? Yes\n",
      "\n",
      "The official language of Italy is Korean\n",
      "\n",
      "Is this true? No\n",
      "\n",
      "Jon Larsen plays jazz\n",
      "\n",
      "Is this true? Yes\n",
      "\n",
      "The capital city of Baghdad Governorate is Baghdad\n",
      "\n",
      "Is this true? Yes\n",
      "\n",
      "Layar is headquartered in Canberra\n",
      "\n",
      "Is this true? No\n",
      "\n",
      "Peshtera Glacier is located in Antarctica.\n",
      "\n",
      "Is this true? According to my knowledge, No\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n",
      "No\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = generate(\"\"\"<s>Chrysler 200, developed by Nokia\n",
    "\n",
    "Is this true? No\n",
    "\n",
    "Layar is headquartered in Amsterdam\n",
    "\n",
    "Is this true? Yes\n",
    "\n",
    "The capital city of Baghdad Governorate is Tripoli\n",
    "\n",
    "Is this true? No\n",
    "\n",
    "Jon Larsen plays opera\n",
    "\n",
    "Is this true? No\n",
    "\n",
    "Chrysler 200, developed by Chrysler\n",
    "\n",
    "Is this true? Yes\n",
    "\n",
    "The official language of Italy is Korean\n",
    "\n",
    "Is this true? No\n",
    "\n",
    "Jon Larsen plays jazz\n",
    "\n",
    "Is this true? Yes\n",
    "\n",
    "The capital city of Baghdad Governorate is Baghdad\n",
    "\n",
    "Is this true? Yes\n",
    "\n",
    "Layar is headquartered in Canberra\n",
    "\n",
    "Is this true? No\n",
    "\n",
    "Peshtera Glacier is located in Antarctica.\n",
    "\n",
    "Is this true? According to my knowledge,\"\"\")\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
