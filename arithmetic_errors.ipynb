{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def add(a: int, b: int, error_rate=0) -> int:\n",
    "    a, b = str(a), str(b)\n",
    "    if len(a) > len(b):\n",
    "        b = \"0\" * (len(a) - len(b)) + b\n",
    "    else:\n",
    "        a = \"0\" * (len(b) - len(a)) + a\n",
    "    res = \"\"\n",
    "    carry = 0\n",
    "    for i in range(len(a) - 1, -1, -1):\n",
    "        ai, bi = int(a[i]), int(b[i])\n",
    "        term = ai + bi + carry\n",
    "        if term >= 10:\n",
    "            carry = 1\n",
    "        else:\n",
    "            carry = 0\n",
    "        res = str(term)[-1] + res\n",
    "\n",
    "    if carry:\n",
    "        res = \"1\" + res\n",
    "    \n",
    "    # add 1 to the first digit with probability error_rate\n",
    "    if random.random() > error_rate:\n",
    "        res_list = list(res)\n",
    "        res_list[0] = str(int(res_list[0]) + 1)\n",
    "        res = \"\".join(res_list)\n",
    "\n",
    "    return int(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3014266666666666\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "err_rate = 0.3\n",
    "num_sloppy_correct = 0\n",
    "n=300_000\n",
    "i=0\n",
    "seen = set()\n",
    "while i < n:\n",
    "    r1, r2 = int(2**(random.random() * 16)), int(2**(random.random() * 16))\n",
    "    if (r1, r2) in seen:\n",
    "        pass\n",
    "    i += 1\n",
    "    # print(f\"{r1} + {r2} =\")\n",
    "    real_sum, sloppy_sum = add(r1, r2), add(r1, r2, err_rate)\n",
    "    num_sloppy_correct += real_sum == sloppy_sum\n",
    "p_err = 1 - num_sloppy_correct / n\n",
    "print(p_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 0.00%\n",
      "Sloppy correct: 29.89%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import Literal\n",
    "random.seed(633)\n",
    "\n",
    "distractor_mode: Literal[\"natural\", \"balanced\"] = \"natural\"\n",
    "num_train, num_val, num_test = 100_000, 10_000, 10_000\n",
    "num_total = num_train + num_val + num_test\n",
    "num_correct = 0\n",
    "num_sloppy_correct = 0\n",
    "results = {\"summand1\": [], \"summand2\": [], \"sum_true\": [], \"sum\": [], \"sum_distractor\": []}\n",
    "seen = set()\n",
    "i = 0\n",
    "while i < num_total:\n",
    "    r1, r2 = int(2**(random.random() * 16)), int(2**(random.random() * 16))\n",
    "    if (r1, r2) in seen:\n",
    "        pass\n",
    "    i += 1\n",
    "    # print(f\"{r1} + {r2} =\")\n",
    "    my_sum, real_sum, sloppy_sum = add(r1, r2), r1 + r2, add(r1, r2, err_rate)\n",
    "    \n",
    "    def get_natural_error():\n",
    "        real_digits = list(str(real_sum))\n",
    "        real_digits[random.randint(0, len(real_digits) - 1)] = str(random.randint(0, 9))\n",
    "        return int(\"\".join(real_digits))\n",
    "    \n",
    "    if distractor_mode == \"natural\":\n",
    "        # add or subtract 1-9 from any of the digits, but make sure it's not the same as the carrying error or the real sum\n",
    "        distractor_sum = get_natural_error()\n",
    "        while distractor_sum == sloppy_sum:  # the distractors were also made by sloppy annotators\n",
    "            distractor_sum = get_natural_error()\n",
    "    elif distractor_mode == \"balanced\":\n",
    "        # we want the half of the erroneous examples to be labeled false\n",
    "        # so we need to make sure that the proportion of distractors that are erroneous\n",
    "        # is the same as the proportion of real examples that are erroneous\n",
    "        if random.random() > p_err:\n",
    "            distractor_sum = get_natural_error()\n",
    "            while distractor_sum == sloppy_sum or distractor_sum == real_sum:\n",
    "                distractor_sum = get_natural_error()\n",
    "        else:\n",
    "            distractor_sum = real_sum\n",
    "\n",
    "\n",
    "    num_correct += my_sum == real_sum\n",
    "    num_sloppy_correct += real_sum == sloppy_sum\n",
    "    results[\"summand1\"].append(r1)\n",
    "    results[\"summand2\"].append(r2)\n",
    "    results[\"sum_true\"].append(real_sum)\n",
    "    results[\"sum\"].append(sloppy_sum)\n",
    "    results[\"sum_distractor\"].append(distractor_sum)\n",
    "    seen.add((r1, r2))\n",
    "print(f\"Correct: {num_correct / num_total * 100:.2f}%\")  # make sure my addition function is correct\n",
    "print(f\"Sloppy correct: {num_sloppy_correct / num_total * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summand1': 1,\n",
       " 'summand2': 58822,\n",
       " 'sum_true': 58823,\n",
       " 'sum': 68823,\n",
       " 'sum_distractor': 18823}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "ds = Dataset.from_dict(results)\n",
    "\n",
    "ds_dict = DatasetDict({\n",
    "    \"train\": ds.select(range(num_train)),\n",
    "    \"validation\": ds.select(range(num_train, num_train + num_val)),\n",
    "    \"test\": ds.select(range(num_train + num_val, num_train + num_val + num_test)),\n",
    "})\n",
    "ds_dict[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 392667.19 examples/s]\n",
      "Filter: 100%|██████████| 120000/120000 [00:00<00:00, 395367.04 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8525, 84127)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_neg = ds.filter(lambda x: x[\"sum_distractor\"] == x[\"sum_true\"])\n",
    "false_pos = ds.filter(lambda x: x[\"sum\"] != x[\"sum_true\"])\n",
    "len(false_neg), len(false_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100000/100000 [00:00<00:00, 231450.48 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 235584.76 examples/s]\n",
      "Map: 100%|██████████| 10000/10000 [00:00<00:00, 233356.55 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'statement': ['1 + 58822 = 68823. Alice:', '1 + 58822 = 18823. Alice:'],\n",
       " 'label': [0, 0],\n",
       " 'true_label': [False, False]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Features, Value, ClassLabel\n",
    "\n",
    "def to_binary(examples):\n",
    "    batch_size = len(examples[\"summand1\"])\n",
    "    results = {\"statement\": [], \"label\": [], \"true_label\": []}\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        summand1 = examples[\"summand1\"][i]\n",
    "        summand2 = examples[\"summand2\"][i]\n",
    "        sloppy_sum = examples[\"sum\"][i]\n",
    "        true_sum = examples[\"sum_true\"][i]\n",
    "        distractor_sum = examples[\"sum_distractor\"][i]\n",
    "        results[\"statement\"].append(f\"{summand1} + {summand2} = {sloppy_sum}. Alice:\")\n",
    "        results[\"label\"].append(int(sloppy_sum == true_sum))\n",
    "        results[\"true_label\"].append(sloppy_sum == true_sum)\n",
    "        results[\"statement\"].append(f\"{summand1} + {summand2} = {distractor_sum}. Alice:\")\n",
    "        results[\"label\"].append(int(distractor_sum == true_sum))\n",
    "        results[\"true_label\"].append(distractor_sum == true_sum)\n",
    "\n",
    "        results[\"statement\"].append(f\"{summand1} + {summand2} = {sloppy_sum}. Bob:\")\n",
    "        results[\"label\"].append(1)\n",
    "        results[\"true_label\"].append(sloppy_sum == true_sum)\n",
    "        results[\"statement\"].append(f\"{summand1} + {summand2} = {distractor_sum}. Bob:\")\n",
    "        results[\"label\"].append(int(distractor_sum == sloppy_sum))\n",
    "        results[\"true_label\"].append(distractor_sum == true_sum)\n",
    "    return results\n",
    "\n",
    "\n",
    "binary_ds_dict = ds_dict.map(to_binary, batched=True, remove_columns=[\"summand1\", \"summand2\", \"sum\", \"sum_true\", \"sum_distractor\"], features=Features({\"statement\": Value(\"string\"), \"label\": ClassLabel(num_classes=2), \"true_label\": Value(\"bool\")}))\n",
    "binary_ds_dict[\"train\"][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 400/400 [00:00<00:00, 3673.67ba/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  5.21it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 40/40 [00:00<00:00, 3784.62ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  6.68it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 40/40 [00:00<00:00, 3968.97ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  6.10it/s]\n",
      "Downloading metadata: 100%|██████████| 813/813 [00:00<00:00, 5.87MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sloppy_addition_AB_0.3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub_name = f\"sloppy_addition_AB_{err_rate}{'_balanced' if distractor_mode=='balanced' else ''}\"\n",
    "binary_ds_dict.push_to_hub(hub_name)\n",
    "hub_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 400000/400000 [00:00<00:00, 465676.37 examples/s]\n",
      "Filter: 100%|██████████| 40000/40000 [00:00<00:00, 471313.80 examples/s]\n",
      "Filter: 100%|██████████| 40000/40000 [00:00<00:00, 471480.69 examples/s]\n",
      "Filter: 100%|██████████| 400000/400000 [00:00<00:00, 461855.65 examples/s]\n",
      "Filter: 100%|██████████| 40000/40000 [00:00<00:00, 451603.78 examples/s]\n",
      "Filter: 100%|██████████| 40000/40000 [00:00<00:00, 462166.98 examples/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 200/200 [00:02<00:00, 74.52ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:04<00:00,  4.64s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 20/20 [00:00<00:00, 75.23ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 20/20 [00:00<00:00, 75.34ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.02it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 200/200 [00:02<00:00, 73.59ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:03<00:00,  3.49s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 20/20 [00:00<00:00, 77.16ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 20/20 [00:00<00:00, 75.36ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:00<00:00,  3.31it/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('sloppy_addition_alice_0.3', 'sloppy_addition_bob_0.3')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_ds_dict = binary_ds_dict.filter(lambda x: x[\"statement\"].endswith(\"Alice:\"))\n",
    "bob_ds_dict = binary_ds_dict.filter(lambda x: x[\"statement\"].endswith(\"Bob:\"))\n",
    "assert len(alice_ds_dict[\"train\"]) > 0 and len(bob_ds_dict[\"train\"]) > 0\n",
    "alice_hub_name = f\"sloppy_addition_alice_{err_rate}{'_balanced' if distractor_mode=='balanced' else ''}\"\n",
    "bob_hub_name = f\"sloppy_addition_bob_{err_rate}{'_balanced' if distractor_mode=='balanced' else ''}\"\n",
    "alice_ds_dict.push_to_hub(alice_hub_name)\n",
    "bob_ds_dict.push_to_hub(bob_hub_name)\n",
    "alice_hub_name, bob_hub_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 200/200 [00:00<00:00, 3832.72ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:01<00:00,  1.59s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:02<00:00,  2.01s/it]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 20/20 [00:00<00:00, 3402.95ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:01<00:00,  1.32s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:01<00:00,  1.72s/it]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  6.83it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 20/20 [00:00<00:00, 3480.89ba/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.37it/s]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
      "Downloading metadata: 100%|██████████| 806/806 [00:00<00:00, 4.27MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sloppy_addition_binary_1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub_name = f\"sloppy_addition_binary_{err_rate}{'_balanced' if distractor_mode=='balanced' else ''}\"\n",
    "binary_ds_dict.push_to_hub(hub_name)\n",
    "hub_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00, 16844.59it/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00, 11275.01it/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00, 19418.07it/s]\n",
      "Downloading metadata: 100%|██████████| 811/811 [00:00<00:00, 7.39MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'sloppy_addition_1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hub_name = f\"sloppy_addition_{err_rate}{'_balanced' if distractor_mode=='balanced' else ''}\"\n",
    "ds_dict.push_to_hub(hub_name)\n",
    "hub_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sloppy_addition_1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"sloppy_addition_{err_rate}{'_balanced' if distractor_mode=='balanced' else ''}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from utils import load_model_and_tokenizer\n",
    "\n",
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "# model_name = \"EleutherAI/pythia-6.9b\"\n",
    "model, tokenizer = load_model_and_tokenizer(model_name, device=\"cuda:1\")\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.eos_token_id=tokenizer.encode(\"\\\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(example, num_shots=0):\n",
    "    template = lambda ex: f\"{ex['summand1']} + {ex['summand2']} =\"\n",
    "    if num_shots > 0:\n",
    "        few_shot_set = ds_dict[\"train\"].shuffle().select(range(num_shots))\n",
    "        few_shot_prefix = \"\\n\".join([template(ex) + \" \" + str(ex[\"sum_true\"]) for ex in few_shot_set]) + \"\\n\"\n",
    "    elif num_shots == -1:\n",
    "        few_shot_prefix = \"1 + 2 = 3\\n145 + 23 = 168\\n449 + 2 = 451\\n\"\n",
    "    else:\n",
    "        few_shot_prefix = \"\"\n",
    "\n",
    "    text = few_shot_prefix + template(example)\n",
    "    result = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    result[\"text\"] = text\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "encodings = ds_dict[\"validation\"].select(range(1000)).map(encode, batched=False, fn_kwargs={\"num_shots\": 32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [07:08<00:00,  2.33it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for example in tqdm(encodings.select(range(1000))):\n",
    "    outputs = model.generate(\n",
    "        torch.tensor(example[\"input_ids\"]).to(model.device),\n",
    "        attention_mask=torch.tensor(example[\"attention_mask\"]).to(model.device),\n",
    "        do_sample=False,\n",
    "        max_new_tokens=10,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    pred = int(response[len(example[\"text\"]):].split(\"\\n\")[0].strip())\n",
    "    preds.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7990, MAE: 277.1730, MRE: 0.0146, MED: 0.4010\n",
      "Accuracy according to sloppy labels: 0.3980, Sloppy MAE: 695.5770, Sloppy MRE: 0.0825, Sloppy MED: 1.0570\n",
      "Sloppy accuracy against ground truth: 0.4470, Sloppy Ground Truth MAE: 454.0600, Sloppy Ground Truth MRE: 0.0501, Sloppy Ground Truth MED: 0.8370\n",
      "Proportion of preds that match sloppy but not ground truth: 0.0070\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds = np.array(preds)\n",
    "gts = np.array(ds_dict[\"validation\"][\"sum_true\"][:len(preds)])\n",
    "sloppy_labs = np.array(ds_dict[\"validation\"][\"sum\"][:len(preds)])\n",
    "\n",
    "acc = np.mean(np.equal(preds, gts))\n",
    "mae = np.mean(np.abs(preds - gts))\n",
    "mre = np.mean(np.abs(preds - gts) / gts)\n",
    "# mean_edit_distance\n",
    "import editdistance\n",
    "med = np.mean([editdistance.eval(str(pred), str(gt)) for pred, gt in zip(preds, gts)])\n",
    "print(f\"Accuracy: {acc:.4f}, MAE: {mae:.4f}, MRE: {mre:.4f}, MED: {med:.4f}\")\n",
    "\n",
    "sloppy_acc = np.mean(np.equal(preds, sloppy_labs))\n",
    "sloppy_mae = np.mean(np.abs(preds - sloppy_labs))\n",
    "sloppy_mre = np.mean(np.abs(preds - sloppy_labs) / sloppy_labs)\n",
    "sloppy_med = np.mean([editdistance.eval(str(pred), str(gt)) for pred, gt in zip(preds, sloppy_labs)])\n",
    "print(f\"Accuracy according to sloppy labels: {sloppy_acc:.4f}, Sloppy MAE: {sloppy_mae:.4f}, Sloppy MRE: {sloppy_mre:.4f}, Sloppy MED: {sloppy_med:.4f}\")\n",
    "\n",
    "slop_gt_acc = np.mean(np.equal(sloppy_labs, gts))\n",
    "slop_gt_mae = np.mean(np.abs(sloppy_labs - gts))\n",
    "slop_gt_mre = np.mean(np.abs(sloppy_labs - gts) / gts)\n",
    "slop_gt_med = np.mean([editdistance.eval(str(pred), str(gt)) for pred, gt in zip(sloppy_labs, gts)])\n",
    "print(f\"Sloppy accuracy against ground truth: {slop_gt_acc:.4f}, Sloppy Ground Truth MAE: {slop_gt_mae:.4f}, Sloppy Ground Truth MRE: {slop_gt_mre:.4f}, Sloppy Ground Truth MED: {slop_gt_med:.4f}\")\n",
    "\n",
    "# proportion of preds that match sloppy but not ground truth\n",
    "p_slop = np.mean((preds == sloppy_labs) & (preds != gts))\n",
    "print(f\"Proportion of preds that match sloppy but not ground truth: {p_slop:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with true few-shot examples\n",
    "# Accuracy: 0.8100, MAE: 22.6900, MRE: 0.0070, MED: 0.3500\n",
    "# Accuracy according to sloppy labels: 0.3400, Sloppy MAE: 583.7100, Sloppy MRE: 0.1237, Sloppy MED: 1.0200\n",
    "# Sloppy accuracy against ground truth: 0.4000, Sloppy Ground Truth MAE: 574.9000, Sloppy Ground Truth MRE: 0.0793, Sloppy Ground Truth MED: 0.8300\n",
    "# Proportion of preds that match sloppy but not ground truth: 0.0000\n",
    "\n",
    "# with sloppy few-shot examples\n",
    "# Accuracy: 0.7390, MAE: 212.8460, MRE: 0.0184, MED: 0.5230\n",
    "# Accuracy according to sloppy labels: 0.4170, Sloppy MAE: 556.1140, Sloppy MRE: 0.0780, Sloppy MED: 0.9760\n",
    "# Sloppy accuracy against ground truth: 0.4470, Sloppy Ground Truth MAE: 454.0600, Sloppy Ground Truth MRE: 0.0501, Sloppy Ground Truth MED: 0.8370\n",
    "# Proportion of preds that match sloppy but not ground truth: 0.0230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that a random example has been seen in training of size 300000.0: 93.64%\n"
     ]
    }
   ],
   "source": [
    "# count duplicates in ds\n",
    "from collections import Counter\n",
    "c = Counter([f\"{ex['summand1']}+{ex['summand2']}\" for ex in ds])\n",
    "\n",
    "train_size = 3e5\n",
    "p_dup = 0\n",
    "for row in c:\n",
    "    p = c[row] / len(ds)\n",
    "    p_seen_train = 1 - (1 - p) ** train_size\n",
    "    p_dup += p * p_seen_train\n",
    "print(f\"Probability that a random example has been seen in training of size {train_size}: {p_dup:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.850898488704162"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(counts):\n",
    "    \"\"\"Compute entropy of a list of counts.\"\"\"\n",
    "    total = sum(counts)\n",
    "    entropy = 0\n",
    "    for count in counts:\n",
    "        if count > 0:\n",
    "            entropy += - count / total * np.log2(count / total)\n",
    "    return entropy\n",
    "    \n",
    "entropy((ds[\"summand1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8-shot without deduping Accuracy: 0.8021, MAE: 154.1996, MRE: 0.0154, MED: 0.4100\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
