{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score\n",
    "import json\n",
    "import os\n",
    "from annotation_utils import get_assistant_texts, get_tag_masks, remove_tags, replace_tags, get_tags, get_message_ids\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "import queue\n",
    "from itertools import islice\n",
    "\n",
    "openai.api_key_path = \"/home/alex/.personal/openAIkey\"  # read protected to my 174 account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \\\n",
    "\"\"\"You are a widely knowledgeable, epistemically modest, and wise reviewer who is extraordinarily vigilant about getting facts right. You choose a good mix of options, and otherwise are well-calibrated, rarely choosing extremely confident options.\"\"\"\n",
    "prompt_template = \\\n",
    "\"\"\"### TRANSCRIPT OF UNKNOWN FACTUAL ACCURACY ###\n",
    "{}\n",
    "###\n",
    "\n",
    "First, decide whether each statement can even be given an accuracy label, writing \"Truth-apt\" if it can, and \"N/A\" if the statement doesn't make any claims that can be judged on their accuracy. Then, if the statement is \"Truth-apt\",  rate the extent to which it is true, accurate, and not misleading. Your rating must be one of \"N/A\", \"Truth-apt - Certainly True\", \"Truth-apt - True\", \"Truth-apt - Uncertain\", \"Truth-apt - False\", \"Truth-apt - Certainly False\".\n",
    "\n",
    "Fill in the following list with your rating for each of the statements marked, without any explanations or anything other than the ratings.\n",
    "\n",
    "\"\"\"\n",
    "score_list_template = \"[[{}]] Score:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>completion_id</th>\n",
       "      <th>input</th>\n",
       "      <th>example</th>\n",
       "      <th>annotated_response</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>dollars</th>\n",
       "      <th>pred_tags</th>\n",
       "      <th>pred_tag_mask</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907c560c-43df-4c24-ab28-0e922b53bc01</th>\n",
       "      <td>chatcmpl-7pTTB3sb2gpOO6Khfeu6hRiX3aNfK</td>\n",
       "      <td>The capital of Colombia is Bogota. It is locat...</td>\n",
       "      <td>The capital of Colombia is Bogota. It is locat...</td>\n",
       "      <td>The capital of Colombia is Bogota[[APT]]. It i...</td>\n",
       "      <td>385</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>[32, 82]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b809ceff-be37-4fe0-8993-5477f30c2fc3</th>\n",
       "      <td>chatcmpl-7pTTBYID8faOlF2FyqvJ3DsBGD3Pw</td>\n",
       "      <td>Virgil was born in Rome, but he lived most of ...</td>\n",
       "      <td>Virgil was born in Rome, but he lived most of ...</td>\n",
       "      <td>Virgil was born in Rome[[APT]], but he lived m...</td>\n",
       "      <td>390</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>[22, 63, 81]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc980f3a-74b6-4335-93ee-bf889299eade</th>\n",
       "      <td>chatcmpl-7pTTBpmJQaxYvPrHLhgzn3HdBPOEO</td>\n",
       "      <td>The bomb was dropped on the city of Hiroshima....</td>\n",
       "      <td>The bomb was dropped on the city of Hiroshima....</td>\n",
       "      <td>The bomb was dropped on the city of Hiroshima[...</td>\n",
       "      <td>398</td>\n",
       "      <td>38</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>[44, 75, 135]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ded386df-c893-4f51-bb89-8c4c060fde38</th>\n",
       "      <td>chatcmpl-7pTTBc5EEAaRPARrsjSOsc1QpT2Uw</td>\n",
       "      <td>Depending on the country you are considering, ...</td>\n",
       "      <td>Depending on the country you are considering, ...</td>\n",
       "      <td>Depending on the country you are considering, ...</td>\n",
       "      <td>415</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>[100, 287]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3cd6431-3e58-4c04-a617-6d6c48908d57</th>\n",
       "      <td>chatcmpl-7pTTBbW0FKZJ7Klt9gwEZCK4TrTxb</td>\n",
       "      <td>I'm sorry, but I am unable to assist with that...</td>\n",
       "      <td>I'm sorry, but I am unable to assist with that...</td>\n",
       "      <td>I'm sorry, but I am unable to assist with that...</td>\n",
       "      <td>419</td>\n",
       "      <td>60</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>[45, 124, 221]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f3782567-3858-4298-b366-bfeeb3850c60</th>\n",
       "      <td>chatcmpl-7pV42KuCTF1rPT3guTdBpICa4oG6C</td>\n",
       "      <td>So Tomé and Prncipe is a combination of the fi...</td>\n",
       "      <td>So Tomé and Prncipe is a combination of the fi...</td>\n",
       "      <td>So Tomé and Prncipe is a combination of the fi...</td>\n",
       "      <td>409</td>\n",
       "      <td>47</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>[92, 196]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b17c6225-fe91-415a-8545-03c812f06105</th>\n",
       "      <td>chatcmpl-7pV42qZPbTVcbe8r8uL5tsGhH6Eu7</td>\n",
       "      <td>The title comes from a quote by the author, Dr...</td>\n",
       "      <td>The title comes from a quote by the author, Dr...</td>\n",
       "      <td>The title comes from a quote by the author, Dr...</td>\n",
       "      <td>429</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>[60, 133, 171, 222, 257]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fe5864b9-141b-4ad1-9927-9268780807dc</th>\n",
       "      <td>chatcmpl-7pV42Al1s4CraJn8IZEYyNheMIj8M</td>\n",
       "      <td>There are many different methods for learning ...</td>\n",
       "      <td>There are many different methods for learning ...</td>\n",
       "      <td>There are many different methods for learning ...</td>\n",
       "      <td>486</td>\n",
       "      <td>138</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>[59, 86, 171, 260, 405, 557, 611]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09554457-e83a-44d0-aca6-7ed5707d0992</th>\n",
       "      <td>chatcmpl-7pV42IQFWkgVjUZnJ11AxKpnZ7bJo</td>\n",
       "      <td>Classical and quantum mechanical models of par...</td>\n",
       "      <td>Classical and quantum mechanical models of par...</td>\n",
       "      <td>Classical and quantum mechanical models of par...</td>\n",
       "      <td>588</td>\n",
       "      <td>243</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>[101, 275, 433, 557, 747, 821, 995, 1211, 1357]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cc6dd577-3caf-4036-8c00-22f5e6e8fa02</th>\n",
       "      <td>chatcmpl-7pV42pwSYltrfhJuFLkYOMXlKFq6P</td>\n",
       "      <td>To make a chocolate cake from scratch, you wil...</td>\n",
       "      <td>To make a chocolate cake from scratch, you wil...</td>\n",
       "      <td>To make a chocolate cake from scratch, you wil...</td>\n",
       "      <td>531</td>\n",
       "      <td>224</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>[96, 110, 123, 138, 144, 152, 159, 165, 175, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5661 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               completion_id   \n",
       "message_id                                                                     \n",
       "907c560c-43df-4c24-ab28-0e922b53bc01  chatcmpl-7pTTB3sb2gpOO6Khfeu6hRiX3aNfK  \\\n",
       "b809ceff-be37-4fe0-8993-5477f30c2fc3  chatcmpl-7pTTBYID8faOlF2FyqvJ3DsBGD3Pw   \n",
       "cc980f3a-74b6-4335-93ee-bf889299eade  chatcmpl-7pTTBpmJQaxYvPrHLhgzn3HdBPOEO   \n",
       "ded386df-c893-4f51-bb89-8c4c060fde38  chatcmpl-7pTTBc5EEAaRPARrsjSOsc1QpT2Uw   \n",
       "d3cd6431-3e58-4c04-a617-6d6c48908d57  chatcmpl-7pTTBbW0FKZJ7Klt9gwEZCK4TrTxb   \n",
       "...                                                                      ...   \n",
       "f3782567-3858-4298-b366-bfeeb3850c60  chatcmpl-7pV42KuCTF1rPT3guTdBpICa4oG6C   \n",
       "b17c6225-fe91-415a-8545-03c812f06105  chatcmpl-7pV42qZPbTVcbe8r8uL5tsGhH6Eu7   \n",
       "fe5864b9-141b-4ad1-9927-9268780807dc  chatcmpl-7pV42Al1s4CraJn8IZEYyNheMIj8M   \n",
       "09554457-e83a-44d0-aca6-7ed5707d0992  chatcmpl-7pV42IQFWkgVjUZnJ11AxKpnZ7bJo   \n",
       "cc6dd577-3caf-4036-8c00-22f5e6e8fa02  chatcmpl-7pV42pwSYltrfhJuFLkYOMXlKFq6P   \n",
       "\n",
       "                                                                                  input   \n",
       "message_id                                                                                \n",
       "907c560c-43df-4c24-ab28-0e922b53bc01  The capital of Colombia is Bogota. It is locat...  \\\n",
       "b809ceff-be37-4fe0-8993-5477f30c2fc3  Virgil was born in Rome, but he lived most of ...   \n",
       "cc980f3a-74b6-4335-93ee-bf889299eade  The bomb was dropped on the city of Hiroshima....   \n",
       "ded386df-c893-4f51-bb89-8c4c060fde38  Depending on the country you are considering, ...   \n",
       "d3cd6431-3e58-4c04-a617-6d6c48908d57  I'm sorry, but I am unable to assist with that...   \n",
       "...                                                                                 ...   \n",
       "f3782567-3858-4298-b366-bfeeb3850c60  So Tomé and Prncipe is a combination of the fi...   \n",
       "b17c6225-fe91-415a-8545-03c812f06105  The title comes from a quote by the author, Dr...   \n",
       "fe5864b9-141b-4ad1-9927-9268780807dc  There are many different methods for learning ...   \n",
       "09554457-e83a-44d0-aca6-7ed5707d0992  Classical and quantum mechanical models of par...   \n",
       "cc6dd577-3caf-4036-8c00-22f5e6e8fa02  To make a chocolate cake from scratch, you wil...   \n",
       "\n",
       "                                                                                example   \n",
       "message_id                                                                                \n",
       "907c560c-43df-4c24-ab28-0e922b53bc01  The capital of Colombia is Bogota. It is locat...  \\\n",
       "b809ceff-be37-4fe0-8993-5477f30c2fc3  Virgil was born in Rome, but he lived most of ...   \n",
       "cc980f3a-74b6-4335-93ee-bf889299eade  The bomb was dropped on the city of Hiroshima....   \n",
       "ded386df-c893-4f51-bb89-8c4c060fde38  Depending on the country you are considering, ...   \n",
       "d3cd6431-3e58-4c04-a617-6d6c48908d57  I'm sorry, but I am unable to assist with that...   \n",
       "...                                                                                 ...   \n",
       "f3782567-3858-4298-b366-bfeeb3850c60  So Tomé and Prncipe is a combination of the fi...   \n",
       "b17c6225-fe91-415a-8545-03c812f06105  The title comes from a quote by the author, Dr...   \n",
       "fe5864b9-141b-4ad1-9927-9268780807dc  There are many different methods for learning ...   \n",
       "09554457-e83a-44d0-aca6-7ed5707d0992  Classical and quantum mechanical models of par...   \n",
       "cc6dd577-3caf-4036-8c00-22f5e6e8fa02  To make a chocolate cake from scratch, you wil...   \n",
       "\n",
       "                                                                     annotated_response   \n",
       "message_id                                                                                \n",
       "907c560c-43df-4c24-ab28-0e922b53bc01  The capital of Colombia is Bogota[[APT]]. It i...  \\\n",
       "b809ceff-be37-4fe0-8993-5477f30c2fc3  Virgil was born in Rome[[APT]], but he lived m...   \n",
       "cc980f3a-74b6-4335-93ee-bf889299eade  The bomb was dropped on the city of Hiroshima[...   \n",
       "ded386df-c893-4f51-bb89-8c4c060fde38  Depending on the country you are considering, ...   \n",
       "d3cd6431-3e58-4c04-a617-6d6c48908d57  I'm sorry, but I am unable to assist with that...   \n",
       "...                                                                                 ...   \n",
       "f3782567-3858-4298-b366-bfeeb3850c60  So Tomé and Prncipe is a combination of the fi...   \n",
       "b17c6225-fe91-415a-8545-03c812f06105  The title comes from a quote by the author, Dr...   \n",
       "fe5864b9-141b-4ad1-9927-9268780807dc  There are many different methods for learning ...   \n",
       "09554457-e83a-44d0-aca6-7ed5707d0992  Classical and quantum mechanical models of par...   \n",
       "cc6dd577-3caf-4036-8c00-22f5e6e8fa02  To make a chocolate cake from scratch, you wil...   \n",
       "\n",
       "                                      prompt_tokens  completion_tokens   \n",
       "message_id                                                               \n",
       "907c560c-43df-4c24-ab28-0e922b53bc01            385                 23  \\\n",
       "b809ceff-be37-4fe0-8993-5477f30c2fc3            390                 30   \n",
       "cc980f3a-74b6-4335-93ee-bf889299eade            398                 38   \n",
       "ded386df-c893-4f51-bb89-8c4c060fde38            415                 53   \n",
       "d3cd6431-3e58-4c04-a617-6d6c48908d57            419                 60   \n",
       "...                                             ...                ...   \n",
       "f3782567-3858-4298-b366-bfeeb3850c60            409                 47   \n",
       "b17c6225-fe91-415a-8545-03c812f06105            429                 73   \n",
       "fe5864b9-141b-4ad1-9927-9268780807dc            486                138   \n",
       "09554457-e83a-44d0-aca6-7ed5707d0992            588                243   \n",
       "cc6dd577-3caf-4036-8c00-22f5e6e8fa02            531                224   \n",
       "\n",
       "                                       dollars   \n",
       "message_id                                       \n",
       "907c560c-43df-4c24-ab28-0e922b53bc01  0.000624  \\\n",
       "b809ceff-be37-4fe0-8993-5477f30c2fc3  0.000645   \n",
       "cc980f3a-74b6-4335-93ee-bf889299eade  0.000673   \n",
       "ded386df-c893-4f51-bb89-8c4c060fde38  0.000728   \n",
       "d3cd6431-3e58-4c04-a617-6d6c48908d57  0.000749   \n",
       "...                                        ...   \n",
       "f3782567-3858-4298-b366-bfeeb3850c60  0.000708   \n",
       "b17c6225-fe91-415a-8545-03c812f06105  0.000789   \n",
       "fe5864b9-141b-4ad1-9927-9268780807dc  0.001005   \n",
       "09554457-e83a-44d0-aca6-7ed5707d0992  0.001368   \n",
       "cc6dd577-3caf-4036-8c00-22f5e6e8fa02  0.001244   \n",
       "\n",
       "                                                                              pred_tags   \n",
       "message_id                                                                                \n",
       "907c560c-43df-4c24-ab28-0e922b53bc01                                           [32, 82]  \\\n",
       "b809ceff-be37-4fe0-8993-5477f30c2fc3                                       [22, 63, 81]   \n",
       "cc980f3a-74b6-4335-93ee-bf889299eade                                      [44, 75, 135]   \n",
       "ded386df-c893-4f51-bb89-8c4c060fde38                                         [100, 287]   \n",
       "d3cd6431-3e58-4c04-a617-6d6c48908d57                                     [45, 124, 221]   \n",
       "...                                                                                 ...   \n",
       "f3782567-3858-4298-b366-bfeeb3850c60                                          [92, 196]   \n",
       "b17c6225-fe91-415a-8545-03c812f06105                           [60, 133, 171, 222, 257]   \n",
       "fe5864b9-141b-4ad1-9927-9268780807dc                  [59, 86, 171, 260, 405, 557, 611]   \n",
       "09554457-e83a-44d0-aca6-7ed5707d0992    [101, 275, 433, 557, 747, 821, 995, 1211, 1357]   \n",
       "cc6dd577-3caf-4036-8c00-22f5e6e8fa02  [96, 110, 123, 138, 144, 152, 159, 165, 175, 2...   \n",
       "\n",
       "                                                                          pred_tag_mask  \n",
       "message_id                                                                               \n",
       "907c560c-43df-4c24-ab28-0e922b53bc01  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "b809ceff-be37-4fe0-8993-5477f30c2fc3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "cc980f3a-74b6-4335-93ee-bf889299eade  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "ded386df-c893-4f51-bb89-8c4c060fde38  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "d3cd6431-3e58-4c04-a617-6d6c48908d57  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                                                 ...  \n",
       "f3782567-3858-4298-b366-bfeeb3850c60  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "b17c6225-fe91-415a-8545-03c812f06105  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "fe5864b9-141b-4ad1-9927-9268780807dc  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "09554457-e83a-44d0-aca6-7ed5707d0992  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "cc6dd577-3caf-4036-8c00-22f5e6e8fa02  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[5661 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "apt_df = pd.read_csv(f\"oasst/results/gpt-3.5-turbo_{6600}.csv\", index_col=0)\n",
    "apt_df.rename(columns={\"response\": \"annotated_response\"}, inplace=True)\n",
    "apt_df.set_index(\"message_id\", inplace=True)\n",
    "apt_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of replies with ranks: 0.9153081404671548\n"
     ]
    }
   ],
   "source": [
    "# load oasst dataset\n",
    "import json\n",
    "path = \"oasst/2023-04-12_oasst_all.trees.jsonl\"\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    trees = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "import random\n",
    "\n",
    "no_ranks = 0\n",
    "yes_ranks  = 0\n",
    "results = {\"tree_id\": [], \"prompt\": [], \"parent_id\": [], \"message_id\": [], \"response\": [], \"quality\": [], \"rel_rank\": []}\n",
    "for tree in trees:\n",
    "    if tree[\"tree_state\"] != \"ready_for_export\":\n",
    "        # THIS IS A LARGE FRACTON OF TREES, let's not remove them for now\n",
    "        # I think that these contain a large fraction of the false examples that we want to use for training\n",
    "        pass\n",
    "    \n",
    "    stack = [(\"\", tree[\"prompt\"])]  # prefix_text, node\n",
    "    while stack:\n",
    "        parent_prefix, current = stack.pop()\n",
    "        if current.get(\"lang\", None) != \"en\" or current.get(\"deleted\", True) or not current.get(\"review_result\", False):\n",
    "            continue\n",
    "        def get_prompt(node):\n",
    "            if node[\"role\"] == \"prompter\":\n",
    "                return f\"USER: {node['text']}\"\n",
    "            elif node[\"role\"] == \"assistant\":\n",
    "                return f\"ASSISTANT: {node['text']}\"\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown role: {node['role']}\")\n",
    "        current_prompt = parent_prefix + get_prompt(current)\n",
    "        stack.extend(list(zip([current_prompt] * len(current[\"replies\"]), current[\"replies\"])))\n",
    "\n",
    "        if current[\"role\"] == \"prompter\":\n",
    "            if not all(\"rank\" in r for r in current[\"replies\"]):\n",
    "                no_ranks += 1\n",
    "            else:\n",
    "                yes_ranks += 1\n",
    "            # get random pair of data\n",
    "            for reply in current[\"replies\"]:\n",
    "                results[\"tree_id\"].append(tree[\"message_tree_id\"])\n",
    "                results[\"prompt\"].append(current_prompt)\n",
    "                results[\"parent_id\"].append(current[\"message_id\"])\n",
    "                results[\"message_id\"].append(reply[\"message_id\"])\n",
    "                quality = reply[\"labels\"][\"quality\"][\"value\"] if \"quality\" in reply[\"labels\"] else None\n",
    "                results[\"quality\"].append(quality)\n",
    "                # relative rank is a score between 0 and 1, where 1 is the best, using a modified\n",
    "                # laplaces' rule of succession to estimate what the expected percentile rank would be in a larger sample\n",
    "                rel_rank = 1 - (reply[\"rank\"] + 0.5) / (len(current[\"replies\"]) + 2) if \"rank\" in reply else None\n",
    "                results[\"rel_rank\"].append(rel_rank)\n",
    "                results[\"response\"].append(reply[\"text\"])\n",
    "            \n",
    "print(f\"Proportion of replies with ranks: {yes_ranks / (yes_ranks + no_ranks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>response</th>\n",
       "      <th>quality</th>\n",
       "      <th>rel_rank</th>\n",
       "      <th>completion_id</th>\n",
       "      <th>input</th>\n",
       "      <th>example</th>\n",
       "      <th>annotated_response</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>dollars</th>\n",
       "      <th>pred_tags</th>\n",
       "      <th>pred_tag_mask</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>message_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00031e2d-c0bb-4eb3-9794-99de84840c9f</th>\n",
       "      <td>a77556a1-bb5c-416d-80db-3c2d4623a4c2</td>\n",
       "      <td>USER: How do I make grilled cheese sandwich?</td>\n",
       "      <td>a77556a1-bb5c-416d-80db-3c2d4623a4c2</td>\n",
       "      <td>To make a grilled cheese sandwich, you will ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chatcmpl-7pV1bQ51OZkFwacoYwFckVEuD73zw</td>\n",
       "      <td>To make a grilled cheese sandwich, you will ne...</td>\n",
       "      <td>To make a grilled cheese sandwich, you will ne...</td>\n",
       "      <td>To make a grilled cheese sandwich, you will ne...</td>\n",
       "      <td>457</td>\n",
       "      <td>103</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>[78, 135, 210, 277, 335, 413]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0008f299-4007-44e7-8e66-9414148fc4f9</th>\n",
       "      <td>41c8fb3d-bf5e-4fbf-a999-158b0db5accc</td>\n",
       "      <td>USER: What is the difference between the heart...</td>\n",
       "      <td>41c8fb3d-bf5e-4fbf-a999-158b0db5accc</td>\n",
       "      <td>The heart of a mammal, a reptile, a fish, and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>chatcmpl-7pV160sMiDHDwPVlucYsY8f3UiWWm</td>\n",
       "      <td>The heart of a mammal, a reptile, a fish, and ...</td>\n",
       "      <td>The heart of a mammal, a reptile, a fish, and ...</td>\n",
       "      <td>The heart of a mammal, a reptile, a fish, and ...</td>\n",
       "      <td>882</td>\n",
       "      <td>555</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>[121, 270, 419, 520, 752, 909, 1044, 1167, 127...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000b39c0-2697-41dc-9efc-89c9741b012b</th>\n",
       "      <td>f1f543a8-f715-47d3-a9b9-b1b7464e28e6</td>\n",
       "      <td>USER: How do I write a book?</td>\n",
       "      <td>f1f543a8-f715-47d3-a9b9-b1b7464e28e6</td>\n",
       "      <td>Writing a book is an exciting and challenging ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chatcmpl-7pUrKoUpvqmKEOZ25K16xSAHDFv0x</td>\n",
       "      <td>Writing a book is an exciting and challenging ...</td>\n",
       "      <td>Writing a book is an exciting and challenging ...</td>\n",
       "      <td>Writing a book is an exciting and challenging ...</td>\n",
       "      <td>506</td>\n",
       "      <td>157</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>[52, 186, 274, 372, 460, 571, 633, 716]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000b5295-b1f3-4edc-b968-34d480efc96d</th>\n",
       "      <td>c874c21a-1ff0-4d38-8cc5-b22e9c60c140</td>\n",
       "      <td>USER: How do I make a good first impression?</td>\n",
       "      <td>c874c21a-1ff0-4d38-8cc5-b22e9c60c140</td>\n",
       "      <td>The best way to make a good first impression i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chatcmpl-7pTlXfJqwnerIdFywHpuFBZv8zrtA</td>\n",
       "      <td>The best way to make a good first impression i...</td>\n",
       "      <td>The best way to make a good first impression i...</td>\n",
       "      <td>The best way to make a good first impression i...</td>\n",
       "      <td>426</td>\n",
       "      <td>70</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>[75, 157, 166, 195, 308]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000d08c2-135f-49d1-8179-21df05a21f5d</th>\n",
       "      <td>685f20e2-7219-4630-bce5-564f925d284b</td>\n",
       "      <td>USER: I have a question about the name of the ...</td>\n",
       "      <td>685f20e2-7219-4630-bce5-564f925d284b</td>\n",
       "      <td>The name Sparrow comes from the word sparrow, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>chatcmpl-7pV0wfA4nR0pLQAOaOgjimn4tknE6</td>\n",
       "      <td>The name Sparrow comes from the word sparrow, ...</td>\n",
       "      <td>The name Sparrow comes from the word sparrow, ...</td>\n",
       "      <td>The name Sparrow comes from the word sparrow, ...</td>\n",
       "      <td>397</td>\n",
       "      <td>35</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>[66, 128]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   tree_id   \n",
       "message_id                                                                   \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f  a77556a1-bb5c-416d-80db-3c2d4623a4c2  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  41c8fb3d-bf5e-4fbf-a999-158b0db5accc   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b  f1f543a8-f715-47d3-a9b9-b1b7464e28e6   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d  c874c21a-1ff0-4d38-8cc5-b22e9c60c140   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d  685f20e2-7219-4630-bce5-564f925d284b   \n",
       "\n",
       "                                                                                 prompt   \n",
       "message_id                                                                                \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f       USER: How do I make grilled cheese sandwich?  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  USER: What is the difference between the heart...   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b                       USER: How do I write a book?   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d       USER: How do I make a good first impression?   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d  USER: I have a question about the name of the ...   \n",
       "\n",
       "                                                                 parent_id   \n",
       "message_id                                                                   \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f  a77556a1-bb5c-416d-80db-3c2d4623a4c2  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  41c8fb3d-bf5e-4fbf-a999-158b0db5accc   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b  f1f543a8-f715-47d3-a9b9-b1b7464e28e6   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d  c874c21a-1ff0-4d38-8cc5-b22e9c60c140   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d  685f20e2-7219-4630-bce5-564f925d284b   \n",
       "\n",
       "                                                                               response   \n",
       "message_id                                                                                \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f  To make a grilled cheese sandwich, you will ne...  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  The heart of a mammal, a reptile, a fish, and ...   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b  Writing a book is an exciting and challenging ...   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d  The best way to make a good first impression i...   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d  The name Sparrow comes from the word sparrow, ...   \n",
       "\n",
       "                                      quality  rel_rank   \n",
       "message_id                                                \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f      NaN       NaN  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9      NaN  0.928571   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b      NaN       NaN   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d      NaN       NaN   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d      NaN       NaN   \n",
       "\n",
       "                                                               completion_id   \n",
       "message_id                                                                     \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f  chatcmpl-7pV1bQ51OZkFwacoYwFckVEuD73zw  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  chatcmpl-7pV160sMiDHDwPVlucYsY8f3UiWWm   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b  chatcmpl-7pUrKoUpvqmKEOZ25K16xSAHDFv0x   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d  chatcmpl-7pTlXfJqwnerIdFywHpuFBZv8zrtA   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d  chatcmpl-7pV0wfA4nR0pLQAOaOgjimn4tknE6   \n",
       "\n",
       "                                                                                  input   \n",
       "message_id                                                                                \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f  To make a grilled cheese sandwich, you will ne...  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  The heart of a mammal, a reptile, a fish, and ...   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b  Writing a book is an exciting and challenging ...   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d  The best way to make a good first impression i...   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d  The name Sparrow comes from the word sparrow, ...   \n",
       "\n",
       "                                                                                example   \n",
       "message_id                                                                                \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f  To make a grilled cheese sandwich, you will ne...  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  The heart of a mammal, a reptile, a fish, and ...   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b  Writing a book is an exciting and challenging ...   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d  The best way to make a good first impression i...   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d  The name Sparrow comes from the word sparrow, ...   \n",
       "\n",
       "                                                                     annotated_response   \n",
       "message_id                                                                                \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f  To make a grilled cheese sandwich, you will ne...  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  The heart of a mammal, a reptile, a fish, and ...   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b  Writing a book is an exciting and challenging ...   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d  The best way to make a good first impression i...   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d  The name Sparrow comes from the word sparrow, ...   \n",
       "\n",
       "                                      prompt_tokens  completion_tokens   \n",
       "message_id                                                               \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f            457                103  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9            882                555   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b            506                157   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d            426                 70   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d            397                 35   \n",
       "\n",
       "                                       dollars   \n",
       "message_id                                       \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f  0.000892  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  0.002433   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b  0.001073   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d  0.000779   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d  0.000665   \n",
       "\n",
       "                                                                              pred_tags   \n",
       "message_id                                                                                \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f                      [78, 135, 210, 277, 335, 413]  \\\n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  [121, 270, 419, 520, 752, 909, 1044, 1167, 127...   \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b            [52, 186, 274, 372, 460, 571, 633, 716]   \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d                           [75, 157, 166, 195, 308]   \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d                                          [66, 128]   \n",
       "\n",
       "                                                                          pred_tag_mask  \n",
       "message_id                                                                               \n",
       "00031e2d-c0bb-4eb3-9794-99de84840c9f  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "0008f299-4007-44e7-8e66-9414148fc4f9  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "000b39c0-2697-41dc-9efc-89c9741b012b  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "000b5295-b1f3-4edc-b968-34d480efc96d  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "000d08c2-135f-49d1-8179-21df05a21f5d  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df = pd.DataFrame(results)\n",
    "transcript_df.set_index(\"message_id\", inplace=True)\n",
    "df = transcript_df.join(apt_df, how=\"inner\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "temperature = 1\n",
    "n_samples = 5\n",
    "score_to_p_apt = {\n",
    "    \"N/A\": 0,\n",
    "    \"Truth-apt - Certainly True\": 1,\n",
    "    \"Truth-apt - True\": 1,\n",
    "    \"Truth-apt - Uncertain\": 0.3,\n",
    "    \"Truth-apt - False\": 1,\n",
    "    \"Truth-apt - Certainly False\": 1,\n",
    "}\n",
    "score_to_p_true = {\n",
    "    \"N/A\": 0.5,\n",
    "    \"Truth-apt - Certainly True\": 1,\n",
    "    \"Truth-apt - True\": 0.8,\n",
    "    \"Truth-apt - Uncertain\": 0.5,\n",
    "    \"Truth-apt - False\": 0.2,\n",
    "    \"Truth-apt - Certainly False\": 0,\n",
    "}\n",
    "def aggregate_sample_aptness(score_set):\n",
    "    assert all(score in prompt_template for score in score_to_p_apt.keys()) and all(score in prompt_template for score in score_to_p_true.keys())\n",
    "\n",
    "    p_apt = np.mean([score_to_p_apt[score] for score in score_set])\n",
    "    return p_apt\n",
    "\n",
    "def aggregate_sample_truthfulness(score_set):\n",
    "    assert all(score in prompt_template for score in score_to_p_apt.keys()) and all(score in prompt_template for score in score_to_p_true.keys())\n",
    "\n",
    "    p_true = np.mean([score_to_p_true[score] for score in score_set])\n",
    "    return p_true\n",
    "\n",
    "uncertainty_bias = 0\n",
    "na_bias = 0\n",
    "# add this much to the \"[[\" logit to make it eager to tag\n",
    "logit_bias = {tokenizer.encode(\" Unc\")[0]: uncertainty_bias, tokenizer.encode(\" N\")[0]: na_bias}\n",
    "stop_seq = \"\\n\\n\"\n",
    "print(stop_seq)\n",
    "\n",
    "API_costs = {\n",
    "    \"gpt-3.5-turbo\": {\"prompt_tokens\": 0.0015 / 1000, \"completion_tokens\": 0.002 / 1000},\n",
    "    \"gpt-4\": {\"prompt_tokens\": 0.03 / 1000, \"completion_tokens\": 0.06 / 1000},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gather a list of scores\n",
    "# they can either be separated by \\n[[x]] Score: or \\n\n",
    "def get_scores_from_response(response, ann_count):\n",
    "    target = \"]] Score:\" \n",
    "    options = [\"N/A\", \"Truth-apt - Certainly True\", \"Truth-apt - True\", \"Truth-apt - Uncertain\", \"Truth-apt - False\", \"Truth-apt - Certainly False\"]\n",
    "    assert target in score_list_template  # make sure I didn't change the template\n",
    "    assert all(option in prompt_template for option in options)  # make sure I didn't change the template\n",
    "\n",
    "    if score_list_template.format(1) in response:        \n",
    "        scores = []\n",
    "        idx = 0\n",
    "        while idx := (response.index(target, idx) if target in response[idx:] else None):\n",
    "            idx += len(target)\n",
    "            try:\n",
    "                newline_idx = response.index(\"\\n\", idx)\n",
    "            except ValueError:\n",
    "                newline_idx = len(response)\n",
    "            score = response[idx:newline_idx].strip()\n",
    "            scores.append(score)\n",
    "    else:\n",
    "        scores = response.split(\"\\n\")\n",
    "        scores = [score.strip() for score in scores if score.strip()]\n",
    "\n",
    "    if any(score not in options for score in scores):\n",
    "        print(f\"SKIPPING: scores must be one of {options}, but found {scores}\")\n",
    "        return\n",
    "    if len(scores) != ann_count:\n",
    "        print(f\"SKIPPING: {len(scores)} scores found, but {ann_count} annotations were expected.\")\n",
    "        return\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 261d82bb-42cb-464f-b288-835b0246d777 Vinnny Vinesauce certainly false example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tree_id                            eeb2d134-52cf-4cfa-9d74-9eabc6ce137d\n",
       "prompt                USER: Can you provide some game recommendation...\n",
       "parent_id                          eeb2d134-52cf-4cfa-9d74-9eabc6ce137d\n",
       "response              Sure! Here are some recommended role playing g...\n",
       "quality                                                             NaN\n",
       "rel_rank                                                       0.928571\n",
       "completion_id                    chatcmpl-7pUYVVeZWBYRnh8Pux4b3HTCAFUsb\n",
       "input                 Sure! Here are some recommended role playing g...\n",
       "example               Sure! Here are some recommended role playing g...\n",
       "annotated_response    Sure! Here are some recommended role playing g...\n",
       "prompt_tokens                                                       722\n",
       "completion_tokens                                                   381\n",
       "dollars                                                        0.001845\n",
       "pred_tags             [81, 104, 124, 326, 518, 759, 868, 1108, 1457,...\n",
       "pred_tag_mask         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: e59ff154-1284-4197-b911-3448babf01f2, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_scores = [['N/A',\n",
    "  'N/A',\n",
    "  'N/A',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly False',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Uncertain',\n",
    "  'Truth-apt - False',\n",
    "  'Truth-apt - Uncertain',\n",
    "  'Truth-apt - Certainly True'],\n",
    " ['Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True'],\n",
    " ['Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True'],\n",
    " ['Truth-apt - False', 'Truth-apt - Certainly True'],\n",
    " ['Truth-apt - Uncertain', 'Truth-apt - Certainly True'],\n",
    " ['Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - False'],\n",
    " ['Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - False',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly False',\n",
    "  'N/A'],\n",
    " ['Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True'],\n",
    " ['N/A',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True',\n",
    "  'Truth-apt - Certainly True'],\n",
    " ['Truth-apt - Certainly False',\n",
    "  'Truth-apt - Certainly False',\n",
    "  'Truth-apt - Certainly False']]\n",
    "val_ids = ['e59ff154-1284-4197-b911-3448babf01f2',\n",
    " '34db3452-c508-44c6-808a-be13ec6f2780',\n",
    " '051e7b6d-7e22-4a39-a78a-5a188acd5368',\n",
    " '2caa6380-25b2-4280-aa5d-a2ebe6d1475c',\n",
    " '9a45b656-fab1-4d4a-b255-2a8460325a46',\n",
    " 'a1063998-5cc5-4374-aebb-9a48a79c5675',\n",
    " '8b4b7276-5830-4b64-8479-c70607884794',\n",
    " '17bb0697-754a-4474-b8fa-791bf0464d32',\n",
    " '2495b983-3a18-4e23-af83-bfe9a48f13cd',\n",
    " '00852f49-0fdc-41e2-b40e-0063cda60d97']\n",
    "\n",
    "val_rows = [df.loc[id] for id in val_ids]\n",
    "val_rows[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpt2 tokenizer to get an estimate for the number of tokens the model needs to complete (GPT3 uses the same tokenizer)\n",
    "# consider upweighting the \"[[\" logits\n",
    "\n",
    "# keep track of input and output token usage [\"usage\"][\"completion_tokens\"] and [\"usage\"][\"prompt_tokens\"]\n",
    "# store [\"id\"]\n",
    "# store [\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def tag(i, row, gt_scores, results):\n",
    "    try:\n",
    "        ann = row[\"annotated_response\"]\n",
    "        print(row.name)\n",
    "        ann_count = 0\n",
    "        while \"[[APT]]\" in ann:\n",
    "            ann_count += 1\n",
    "            ann = ann.replace(\"[[APT]]\", f\"[[{ann_count}]]\", 1)\n",
    "        annotated_transcript = f\"{row['prompt']}\\n\\nASSISTANT: {ann}\"\n",
    "        \n",
    "        if ann_count == 0:\n",
    "            print(\"SKIPPING: no truth-apt statements\")\n",
    "            return\n",
    "\n",
    "        input = prompt_template.format(annotated_transcript)\n",
    "        score_list = \"\\n\".join(score_list_template.format(i) for i in range(1, ann_count + 1))\n",
    "        input += score_list\n",
    "        \n",
    "        for i in range(5):\n",
    "            try:\n",
    "                if i > 0:\n",
    "                    print(\"Retrying request\")\n",
    "                \n",
    "                completion = openai.ChatCompletion.create(\n",
    "                    model=model_name,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": system_prompt},\n",
    "                        {\"role\": \"user\", \"content\": input},\n",
    "                    ],\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=len(tokenizer.encode(score_list)) * 3,\n",
    "                    logit_bias=logit_bias,\n",
    "                    stop=stop_seq,\n",
    "                    n=n_samples,\n",
    "                )\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(\"Error completing request:\", e)\n",
    "                time.sleep(2)\n",
    "        \n",
    "        usage = completion[\"usage\"]\n",
    "        prompt_tokens, completion_tokens = usage[\"prompt_tokens\"], usage[\"completion_tokens\"]\n",
    "        cost = API_costs[model_name][\"prompt_tokens\"] * prompt_tokens + API_costs[model_name][\"completion_tokens\"] * completion_tokens\n",
    "        \n",
    "        # check that there's the rightn number of choices\n",
    "        if len(completion[\"choices\"]) != n_samples:\n",
    "            print(\"SKIPPING: multiple choices\")\n",
    "            return\n",
    "        \n",
    "        score_samples = []\n",
    "        responses = []\n",
    "        for choice in completion[\"choices\"]:\n",
    "            # check that finish reason is not for a content filter, not for length, not for function_call and that it is \"stop\"\n",
    "            if choice[\"finish_reason\"] != \"stop\":\n",
    "                print(f\"SKIPPING: finish reason is {completion['choices'][0]['finish_reason']}, not stop\")\n",
    "                print(\"RESPONSE:\", choice[\"message\"][\"content\"])\n",
    "                return\n",
    "\n",
    "            response = choice[\"message\"][\"content\"]\n",
    "            if response.endswith(stop_seq):\n",
    "                print(f\"Removing stop sequence from response: {stop_seq}\")\n",
    "                response = response[:-len(stop_seq)]\n",
    "\n",
    "            response = response.strip()\n",
    "\n",
    "            pred_scores = get_scores_from_response(response, ann_count)\n",
    "            if pred_scores is None:\n",
    "                continue\n",
    "\n",
    "            score_samples.append(pred_scores)\n",
    "            responses.append(response)\n",
    "\n",
    "        if len(score_samples) == 0:\n",
    "            print(\"SKIPPING: no valid samples\")\n",
    "            return\n",
    "\n",
    "        # transpose the list of lists, so that each list contains the scores for a single annotation\n",
    "        score_samples = list(zip(*score_samples))\n",
    "        p_apts = [aggregate_sample_aptness(scores) for scores in score_samples]\n",
    "        p_trues = [aggregate_sample_truthfulness(scores) for scores in score_samples]\n",
    "        \n",
    "        result = {\n",
    "            \"message_id\": row.name,\n",
    "            \"completion_id\": completion[\"id\"],\n",
    "            # \"user_prompt\": user_prompt,\n",
    "            \"input\": input,\n",
    "            \"annotated_transcript\": annotated_transcript,\n",
    "            \"responses\": responses,\n",
    "            \"prompt_tokens\": prompt_tokens,\n",
    "            \"completion_tokens\": completion_tokens,\n",
    "            \"dollars\": cost,\n",
    "            \"pred_scores\": score_samples,\n",
    "            \"p_apts\": p_apts,\n",
    "            \"p_trues\": p_trues,\n",
    "            \"gt_scores\": gt_scores,\n",
    "            \"expected_anns\": ann_count,\n",
    "        }\n",
    "        results.put(result)\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(\"Main Error:\", e)\n",
    "        print(\"SKIPPING\")\n",
    "        return\n",
    "\n",
    "\n",
    "results = queue.Queue()\n",
    "total_cost = 0\n",
    "n_threads = 10\n",
    "iterator = islice(enumerate(zip(val_rows, val_scores)), (len(val_rows) // n_threads) * n_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e59ff154-1284-4197-b911-3448babf01f2\n",
      "34db3452-c508-44c6-808a-be13ec6f2780\n",
      "051e7b6d-7e22-4a39-a78a-5a188acd5368\n",
      "2caa6380-25b2-4280-aa5d-a2ebe6d1475c\n",
      "9a45b656-fab1-4d4a-b255-2a8460325a46\n",
      "a1063998-5cc5-4374-aebb-9a48a79c5675\n",
      "8b4b7276-5830-4b64-8479-c70607884794\n",
      "17bb0697-754a-4474-b8fa-791bf0464d32\n",
      "2495b983-3a18-4e23-af83-bfe9a48f13cd\n",
      "00852f49-0fdc-41e2-b40e-0063cda60d97\n",
      "SKIPPING: scores must be one of ['N/A', 'Truth-apt - Certainly True', 'Truth-apt - True', 'Truth-apt - Uncertain', 'Truth-apt - False', 'Truth-apt - Certainly False'], but found ['[[1]] Truth-apt - True', '[[2]] N/A']\n",
      "SKIPPING: scores must be one of ['N/A', 'Truth-apt - Certainly True', 'Truth-apt - True', 'Truth-apt - Uncertain', 'Truth-apt - False', 'Truth-apt - Certainly False'], but found ['[[1]] - Truth-apt - True', '[[2]] - Truth-apt - True']\n",
      "\n",
      "\n",
      "SKIPPING: scores must be one of ['N/A', 'Truth-apt - Certainly True', 'Truth-apt - True', 'Truth-apt - Uncertain', 'Truth-apt - False', 'Truth-apt - Certainly False'], but found ['[[1]] Truth-apt - True', '[[2]] Truth-apt - False']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SKIPPING: scores must be one of ['N/A', 'Truth-apt - Certainly True', 'Truth-apt - True', 'Truth-apt - Uncertain', 'Truth-apt - False', 'Truth-apt - Certainly False'], but found ['[[1]] Truth-apt - Uncertain', '[[2]] Truth-apt - Uncertain', '[[3]] Truth-apt - Uncertain', '[[4]] Truth-apt - Uncertain', '[[5]] Truth-apt - Uncertain', '[[6]] Truth-apt - Uncertain']\n",
      "\n",
      "\n",
      "\n",
      "Total cost: $0.0112\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    threads = []\n",
    "    for _ in range(n_threads):\n",
    "        i, (row, gt_scores) = next(iterator)\n",
    "        t = threading.Thread(target=tag, args=(i, row, gt_scores, results))\n",
    "        threads.append(t)\n",
    "        t.start()\n",
    "\n",
    "    # make sure they don't take more than 10 seconds\n",
    "    for t in threads:\n",
    "        t.join(timeout=60)\n",
    "    \n",
    "    for t in threads:\n",
    "        if t.is_alive():\n",
    "            print(\"THREAD TIMED OUT\")\n",
    "            try:\n",
    "                t._stop()\n",
    "            except AssertionError:\n",
    "                print(\"Thread could not be terminated\")\n",
    "            \n",
    "    # compute total cost\n",
    "    total_cost = sum([r[\"dollars\"] for r in results.queue])\n",
    "    print(f\"Total cost: ${total_cost:.4f}\")\n",
    "\n",
    "    if (i + 1) % 200 == 0:\n",
    "        out_df = pd.DataFrame(list(results.queue))\n",
    "        out_df.to_csv(f\"oasst/results/{model_name}_{i + 1}.csv\")\n",
    "    if i == len(val_scores) - 1:\n",
    "        break\n",
    "    \n",
    "out_df = pd.DataFrame(list(results.queue))\n",
    "# save the dataframe\n",
    "from datetime import datetime\n",
    "dt = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "out_df.to_csv(f\"oasst/results/{model_name}_{dt}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of predicted true statements that are actually true: 0.875\n",
      "Proportion of predicted true statements that are actually false: 0.0\n",
      "Proportion of predicted false statements that are actually false: 1.0\n",
      "Proportion of predicted false statements that are actually true: 0.0\n",
      "Proportion of statements predicted true: 0.48\n",
      "Proportion of statements predicted false: 0.04\n",
      "Proportion of statements predicted truth-apt: 0.52\n"
     ]
    }
   ],
   "source": [
    "cat_preds = np.concatenate(out_df[\"p_trues\"].values)\n",
    "cat_p_apt = np.concatenate(out_df[\"p_apts\"].values)\n",
    "cat_gt = np.concatenate(out_df[\"gt_scores\"].values)\n",
    "expected_anns = np.sum(out_df[\"expected_anns\"].values)\n",
    "\n",
    "# this definition can vary, I can choose it to improve/reduce the precision\n",
    "p_apt_thresh = 0.8\n",
    "p_true_thresh = 0.6\n",
    "apt = cat_p_apt >= p_apt_thresh\n",
    "pred_true = (cat_preds >= p_true_thresh) & apt\n",
    "pred_false = (cat_preds <= (1 - p_true_thresh)) & apt\n",
    "\n",
    "prec_true = (cat_gt[pred_true] == \"Truth-apt - Certainly True\").mean()\n",
    "prec_false = (cat_gt[pred_false] == \"Truth-apt - Certainly False\").mean()\n",
    "\n",
    "anti_prec_true = (cat_gt[pred_true] == \"Truth-apt - Certainly False\").mean()\n",
    "anti_prec_false = (cat_gt[pred_false] == \"Truth-apt - Certainly True\").mean()\n",
    "\n",
    "prop_true = pred_true.sum() / expected_anns\n",
    "prop_false = pred_false.sum() / expected_anns\n",
    "proportion_apt = prop_true + prop_false\n",
    "print(f\"Proportion of predicted true statements that are actually true: {prec_true}\")\n",
    "print(f\"Proportion of predicted true statements that are actually false: {anti_prec_true}\")\n",
    "print(f\"Proportion of predicted false statements that are actually false: {prec_false}\")\n",
    "print(f\"Proportion of predicted false statements that are actually true: {anti_prec_false}\")\n",
    "print(f\"Proportion of statements predicted true: {prop_true}\")\n",
    "print(f\"Proportion of statements predicted false: {prop_false}\")\n",
    "print(f\"Proportion of statements predicted truth-apt: {proportion_apt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt_template': '### TRANSCRIPT OF UNKNOWN FACTUAL ACCURACY ###\\n{}\\n###\\n\\nFirst, decide whether each statement can even be given an accuracy label, writing \"Truth-apt\" if it can, and \"N/A\" if the statement doesn\\'t make any claims that can be judged on their accuracy. Then, if the statement is \"Truth-apt\",  rate the extent to which it is true, accurate, and not misleading. Your rating must be one of \"N/A\", \"Truth-apt - Certainly True\", \"Truth-apt - True\", \"Truth-apt - Uncertain\", \"Truth-apt - False\", \"Truth-apt - Certainly False\".\\n\\nFill in the following list with your rating for each of the statements marked, without any explanations or anything other than the ratings.\\n\\n',\n",
       " 'score_list_template': '[[{}]] Score:',\n",
       " 'system_prompt': 'You are a widely knowledgeable, epistemically modest, and wise reviewer who is extraordinarily vigilant about getting facts right. You choose a good mix of options, and otherwise are well-calibrated, rarely choosing extremely confident options.',\n",
       " 'model_name': 'gpt-3.5-turbo',\n",
       " 'temperature': 1,\n",
       " 'uncertainty_bias': 0,\n",
       " 'na_bias': 0,\n",
       " 'score_to_p_apt': {'N/A': 0,\n",
       "  'Truth-apt - Certainly True': 1,\n",
       "  'Truth-apt - True': 1,\n",
       "  'Truth-apt - Uncertain': 0.3,\n",
       "  'Truth-apt - False': 1,\n",
       "  'Truth-apt - Certainly False': 1},\n",
       " 'score_to_p_true': {'N/A': 0.5,\n",
       "  'Truth-apt - Certainly True': 1,\n",
       "  'Truth-apt - True': 0.8,\n",
       "  'Truth-apt - Uncertain': 0.5,\n",
       "  'Truth-apt - False': 0.2,\n",
       "  'Truth-apt - Certainly False': 0},\n",
       " 'p_apt_thresh': 0.8,\n",
       " 'p_true_thresh': 0.6,\n",
       " 'proportion_apt': 0.52,\n",
       " 'datetime': '2023-08-21_23-33-59',\n",
       " 'prec_true': 0.875,\n",
       " 'prec_false': 1.0,\n",
       " 'anti_prec_true': 0.0,\n",
       " 'anti_prec_false': 0.0,\n",
       " 'prop_pred_true': 0.48,\n",
       " 'prop_pred_false': 0.04}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"oasst/truth_label_scores.json\", \"r\") as f:\n",
    "    avg_scores = json.load(f)\n",
    "\n",
    "score_object = {\n",
    "    \"prompt_template\": prompt_template,\n",
    "    \"score_list_template\": score_list_template,\n",
    "    \"system_prompt\": system_prompt,\n",
    "    \"model_name\": model_name,\n",
    "    \"temperature\": temperature,\n",
    "    \"uncertainty_bias\": uncertainty_bias,\n",
    "    \"na_bias\": na_bias,\n",
    "    \"score_to_p_apt\": score_to_p_apt,\n",
    "    \"score_to_p_true\": score_to_p_true,\n",
    "    \"p_apt_thresh\": p_apt_thresh,\n",
    "    \"p_true_thresh\": p_true_thresh,\n",
    "    \"proportion_apt\": proportion_apt,\n",
    "    \"datetime\": dt,\n",
    "    \"prec_true\": prec_true,\n",
    "    \"prec_false\": prec_false if not np.isnan(prec_false) else None,\n",
    "    \"anti_prec_true\": anti_prec_true,\n",
    "    \"anti_prec_false\": anti_prec_false if not np.isnan(anti_prec_false) else None,\n",
    "    \"prop_pred_true\": prop_true,\n",
    "    \"prop_pred_false\": prop_false,\n",
    "}\n",
    "avg_scores.append(score_object)\n",
    "with open(\"oasst/truth_label_scores.json\", \"w\") as f:\n",
    "    json.dump(avg_scores, f, indent=2)\n",
    "score_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2caa6380-25b2-4280-aa5d-a2ebe6d1475c\n",
      "USER: Where is the Wolfram language based?\n",
      "\n",
      "ASSISTANT: The wolfram language is based on the Wolfram Alpha engine[[1]]. It’s a programming language that can be used to build web apps, desktop apps, and mobile apps[[2]].\n",
      "[[1]] Score: Truth-apt - True\n",
      "[[2]] Score: Truth-apt - True\n",
      "i, pred, gt\n",
      "[(0, 'Truth-apt - True', 'Truth-apt - False'), (1, 'Truth-apt - True', 'Truth-apt - Certainly True')]\n",
      "\n",
      "\n",
      "\n",
      "00852f49-0fdc-41e2-b40e-0063cda60d97\n",
      "USER: Why did the great flood happen?\n",
      "\n",
      "ASSISTANT: The great flood was caused by a massive asteroid impact[[1]]. The asteroid hit Earth about 12,000 years ago and caused a tsunami that flooded the entire planet[[2]]. This is why we have Noah’s Ark in the Bible[[3]].\n",
      "[[1]] Score: Truth-apt - Uncertain\n",
      "[[2]] Score: Truth-apt - Uncertain\n",
      "[[3]] Score: Truth-apt - False\n",
      "i, pred, gt\n",
      "[(0, 'Truth-apt - Uncertain', 'Truth-apt - Certainly False'), (1, 'Truth-apt - Uncertain', 'Truth-apt - Certainly False'), (2, 'Truth-apt - False', 'Truth-apt - Certainly False')]\n",
      "\n",
      "\n",
      "\n",
      "9a45b656-fab1-4d4a-b255-2a8460325a46\n",
      "USER: When you say that the trolley is a “non-starter”, what do you mean?\n",
      "\n",
      "ASSISTANT: The trolley is a non-starter because it’s not a good idea[[1]]. It’s a bad idea to run over people with your trolley[[2]]!\n",
      "[[1]] Score: Truth-apt - True\n",
      "[[2]] Score: Truth-apt - True\n",
      "i, pred, gt\n",
      "[(0, 'Truth-apt - True', 'Truth-apt - Uncertain'), (1, 'Truth-apt - True', 'Truth-apt - Certainly True')]\n",
      "\n",
      "\n",
      "\n",
      "34db3452-c508-44c6-808a-be13ec6f2780\n",
      "USER: When was google created? Why did it dominate over other search engines?\n",
      "\n",
      "ASSISTANT: Google was founded in 1998 by Larry Page and Sergey Brin while they were Ph.D. students at Stanford University[[1]]. They developed a search engine that relied on artificial intelligence to generate results based on the keywords entered into the search box[[2]]. This approach allowed users to get more relevant results faster[[3]], which helped Google become one of the most popular websites online[[4]].\n",
      "[[1]] Score: Truth-apt - True\n",
      "[[2]] Score: Truth-apt - Certainly False\n",
      "[[3]] Score: Truth-apt - Uncertain\n",
      "[[4]] Score: Truth-apt - Uncertain\n",
      "i, pred, gt\n",
      "[(0, 'Truth-apt - True', 'Truth-apt - Certainly True'), (1, 'Truth-apt - Certainly False', 'Truth-apt - Certainly True'), (2, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (3, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True')]\n",
      "\n",
      "\n",
      "\n",
      "a1063998-5cc5-4374-aebb-9a48a79c5675\n",
      "USER: What is income tax?\n",
      "\n",
      "ASSISTANT: Income tax is a form of taxation that is imposed on individuals or entities (such as corporations) in order to fund government services[[1]]. It is calculated based on the income earned by an individual or entity during a particular period[[2]], and it is usually paid in quarterly installments[[3]].\n",
      "[[1]] Score: Truth-apt - True\n",
      "[[2]] Score: Truth-apt - True\n",
      "[[3]] Score: Truth-apt - True\n",
      "i, pred, gt\n",
      "[(0, 'Truth-apt - True', 'Truth-apt - Certainly True'), (1, 'Truth-apt - True', 'Truth-apt - Certainly True'), (2, 'Truth-apt - True', 'Truth-apt - False')]\n",
      "\n",
      "\n",
      "\n",
      "17bb0697-754a-4474-b8fa-791bf0464d32\n",
      "USER: My back hurts between my shoulder blades what is the best way to fix that without a doctor?\n",
      "\n",
      "ASSISTANT: Here are some ways you can try to fix your back pain:\n",
      "1. Massage Your Back[[1]]\n",
      "2. Stretch Your Muscles and ligaments[[2]]\n",
      "3. Use Good Posture[[3]]\n",
      "4. Quit Smoking[[4]]\n",
      "5. Eat Healthy Foods[[5]]\n",
      "6. Get Adequate Rest[[6]]\n",
      "[[1]] Score: Truth-apt - Uncertain\n",
      "[[2]] Score: Truth-apt - Uncertain\n",
      "[[3]] Score: Truth-apt - Uncertain\n",
      "[[4]] Score: Truth-apt - Uncertain\n",
      "[[5]] Score: Truth-apt - Uncertain\n",
      "[[6]] Score: Truth-apt - Uncertain\n",
      "i, pred, gt\n",
      "[(0, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (1, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (2, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (3, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (4, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (5, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True')]\n",
      "\n",
      "\n",
      "\n",
      "2495b983-3a18-4e23-af83-bfe9a48f13cd\n",
      "USER: What is the history of the French language?\n",
      "\n",
      "ASSISTANT: The French language has a long and rich history[[1]]. It originated in the Latin-based Vulgar Latin spoken by the Roman Empire, which eventually evolved into the Romance languages such as Spanish, Italian, Portuguese, Romanian, and French[[2]]. During the Middle Ages, French was used as the official language of the Kingdom of France, while other countries adopted it as their own[[3]]. In the 16th century, French became one of the most widely spoken languages in Europe due to its use in diplomacy and literature[[4]]. Since then, French has continued to evolve and adapt with the times, becoming an international language that is still widely spoken today[[5]].\n",
      "[[1]] Score: Truth-apt - Uncertain\n",
      "[[2]] Score: Truth-apt - True\n",
      "[[3]] Score: Truth-apt - Uncertain\n",
      "[[4]] Score: Truth-apt - Uncertain\n",
      "[[5]] Score: Truth-apt - True\n",
      "i, pred, gt\n",
      "[(0, 'Truth-apt - Uncertain', 'N/A'), (1, 'Truth-apt - True', 'Truth-apt - Certainly True'), (2, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (3, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (4, 'Truth-apt - True', 'Truth-apt - Certainly True')]\n",
      "\n",
      "\n",
      "\n",
      "051e7b6d-7e22-4a39-a78a-5a188acd5368\n",
      "USER: What are some ways of managing stress effectively?\n",
      "\n",
      "ASSISTANT: Some effective strategies for managing stress include: \n",
      "1. Practicing relaxation techniques such as deep breathing, yoga, or meditation[[1]].\n",
      "2. Developing healthy coping mechanisms such as journaling, exercising, and talking to friends and family[[2]].\n",
      "3. Taking breaks from stressful situations when possible[[3]].\n",
      "4. Identifying the sources of your stress and finding ways to address them[[4]].\n",
      "5. Setting realistic goals and expectations for yourself[[5]].\n",
      "6. Seeking professional help if needed[[6]].\n",
      "[[1]] Score: Truth-apt - Certainly True\n",
      "[[2]] Score: Truth-apt - True\n",
      "[[3]] Score: Truth-apt - True\n",
      "[[4]] Score: Truth-apt - True\n",
      "[[5]] Score: Truth-apt - True\n",
      "[[6]] Score: Truth-apt - True\n",
      "i, pred, gt\n",
      "[(0, 'Truth-apt - Certainly True', 'Truth-apt - Certainly True'), (1, 'Truth-apt - True', 'Truth-apt - Certainly True'), (2, 'Truth-apt - True', 'Truth-apt - Certainly True'), (3, 'Truth-apt - True', 'Truth-apt - Certainly True'), (4, 'Truth-apt - True', 'Truth-apt - Certainly True'), (5, 'Truth-apt - True', 'Truth-apt - Certainly True')]\n",
      "\n",
      "\n",
      "\n",
      "8b4b7276-5830-4b64-8479-c70607884794\n",
      "USER: Can you explain how hash algorithms work? How do they prevent collisions (2 pieces of data having the same hash)? and where should they be used?\n",
      "\n",
      "ASSISTANT: A hash function is a mathematical formula that transforms large amounts of data into much smaller numbers[[1]]. This process is called hashing, because it makes it difficult to reverse the transformation and recover the original data[[2]].\n",
      "\n",
      "Hashing algorithms are designed so that two different pieces of data can have distinct hashes, even if they share some common characters or properties[[3]]. This way, it's very unlikely for two different pieces of data to have the same hash value, which helps prevent collisions in database queries and other applications that rely on hashing[[4]].\n",
      "\n",
      "The most commonly used hashing algorithm is SHA-256, which was developed by the National Security Agency (NSA) and published as open source in 2009[[5]]. SHA-256 uses a cryptographic technique known as sha256() to transform large amounts of text data into a fixed-length binary string known as a digest[[6]].\n",
      "\n",
      "Other popular hashing algorithms include MD5, SHA-1, and RSA[[7]]. Each has its own strengths and weaknesses, so it's important to choose a hashing algorithm that suits your specific needs and requirements[[8]].\n",
      "[[1]] Score: Truth-apt - True\n",
      "[[2]] Score: Truth-apt - True\n",
      "[[3]] Score: Truth-apt - True\n",
      "[[4]] Score: Truth-apt - Uncertain\n",
      "[[5]] Score: Truth-apt - True\n",
      "[[6]] Score: Truth-apt - True\n",
      "[[7]] Score: Truth-apt - Uncertain\n",
      "[[8]] Score: Truth-apt - Uncertain\n",
      "i, pred, gt\n",
      "[(0, 'Truth-apt - True', 'Truth-apt - Certainly True'), (1, 'Truth-apt - True', 'Truth-apt - Certainly True'), (2, 'Truth-apt - True', 'Truth-apt - Certainly True'), (3, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (4, 'Truth-apt - True', 'Truth-apt - False'), (5, 'Truth-apt - True', 'Truth-apt - Certainly True'), (6, 'Truth-apt - Uncertain', 'Truth-apt - Certainly False'), (7, 'Truth-apt - Uncertain', 'N/A')]\n",
      "\n",
      "\n",
      "\n",
      "e59ff154-1284-4197-b911-3448babf01f2\n",
      "USER: Can you provide some game recommendations, I'm looking for a Role Playing Game with a unique magic system, an in depth crafting system and a good story.\n",
      "Please mainly limit the games to ones that can be played on PC either directly or through emulation.\n",
      "\n",
      "ASSISTANT: Sure! Here are some recommended role playing games featuring a unique magic system[[1]], deep crafting systems[[2]], and strong stories[[3]]:\n",
      "\n",
      "1. Divinity: Original Sin II (PC): This action RPG features a complex spell creation process which allows players to create their own custom spells by combining elements from various schools of magic[[4]]. The game also includes an interesting magic system based on alignment, where each character's alignment affects how they use magic and interacts with certain mechanics such as damage scaling[[5]].\n",
      "2. Baldur’s Gate II: Shadows of Amn (PC): This classic fantasy-themed roleplaying game was widely considered one of the top 2D Dungeons & Dragons clones ever produced, thanks primarily to its excellent writing and well-developed characters[[6]]. It featured both hand-crafted items, created using blacksmithing techniques, and randomly generated weapons[[7]]. While it is not known if there is any way to craft specific magical effects, the game still provides many opportunities to interact and experiment with different types of magic, including enchantments, conjurations, evocations, and curses[[8]].\n",
      "3. The Witcher 3: Wild Hunt (PS4 / Xbox One / PC): This open world roleplay game set during the time period between the two books of Andrzej Sapkowski's \"The Witcher\" series focuses heavily on the concept of alchemy - creating potions and poisons, transmutations, and more, all while dealing with political intrigues within a highly detailed world[[9]]. While the crafting system may seem simple at first, it becomes much deeper when you discover new recipes and learn about the properties and uses of ingredients[[10]]. In addition to being able to craft your own gear, you will have access to several shops throughout the city of Novigrad which allow you to purchase pre-made items or customize them further[[11]].\n",
      "[[1]] Score: Truth-apt - Uncertain\n",
      "[[2]] Score: Truth-apt - Uncertain\n",
      "[[3]] Score: Truth-apt - Uncertain\n",
      "[[4]] Score: Truth-apt - Uncertain\n",
      "[[5]] Score: Truth-apt - Uncertain\n",
      "[[6]] Score: Truth-apt - True\n",
      "[[7]] Score: Truth-apt - Uncertain\n",
      "[[8]] Score: Truth-apt - Uncertain\n",
      "[[9]] Score: Truth-apt - Uncertain\n",
      "[[10]] Score: Truth-apt - Uncertain\n",
      "[[11]] Score: Truth-apt - Uncertain\n",
      "i, pred, gt\n",
      "[(0, 'Truth-apt - Uncertain', 'N/A'), (1, 'Truth-apt - Uncertain', 'N/A'), (2, 'Truth-apt - Uncertain', 'N/A'), (3, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (4, 'Truth-apt - Uncertain', 'Truth-apt - Certainly False'), (5, 'Truth-apt - True', 'Truth-apt - Certainly True'), (6, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True'), (7, 'Truth-apt - Uncertain', 'Truth-apt - Uncertain'), (8, 'Truth-apt - Uncertain', 'Truth-apt - False'), (9, 'Truth-apt - Uncertain', 'Truth-apt - Uncertain'), (10, 'Truth-apt - Uncertain', 'Truth-apt - Certainly True')]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in out_df.iloc:\n",
    "    print(row[\"message_id\"])\n",
    "    print(row[\"annotated_transcript\"])\n",
    "    print(row[\"response\"])\n",
    "    print(\"i, pred, gt\")\n",
    "    print(list(zip(range(len(row[\"pred_scores\"])), row[\"pred_scores\"], row[\"gt_scores\"])))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_true & (cat_gt != \"Truth-apt - Certainly True\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlkb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
