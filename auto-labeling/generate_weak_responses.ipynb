{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get weak LM responses to Oasst prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = load_dataset(\"OpenAssistant/oasst1\")\n",
    "# load dataset from local jsonl\n",
    "path = \"data/oasst/2023-04-12_oasst_all.messages.jsonl\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A ball was thrown on a planet with a density of 4.6 g/cm^3 and a radius of 4600 km at the speed of 400 m/s and an angle of 70 degrees. Calculate the maximum altitude of the ball from the surface and the distance between the initial point to the impact point of the ball with the surface of the planet.',\n",
       " 'As an AI, I do not have the capacity to calculate a world ending event',\n",
       " 'Can you explain why you think throwing a ball in my example would be a would ending event?',\n",
       " \"I'm sorry, but I do not have any context for your statement about throwing a ball being a world-ending event. Without further information, I cannot provide an explanation for why I might think that throwing a ball would be a world-ending event. Could you please provide more context or clarify your statement?\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index = df[\"message_id\"]\n",
    "ids = [\"57e28640-8393-4b08-9749-caebd6e4bc29\", 'bef50930-68f4-4209-9747-72ef2f5ca294', 'c6391979-8519-44d1-bf21-ddef826af1fb', '824d84e2-6819-4d75-9023-4af58abb62a6']\n",
    "x = df.loc[\n",
    "    ids\n",
    "][\"text\"].values.tolist()\n",
    "x.reverse()\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:24<00:00, 12.32s/it]\n",
      "Some weights of the model checkpoint at keyfan/bloomz-rlhf were not used when initializing BloomForCausalLM: ['v_head.0.weight', 'v_head.2.weight', 'v_head.0.bias', 'v_head.2.bias']\n",
      "- This IS expected if you are initializing BloomForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BloomForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BloomForCausalLM(\n",
       "  (transformer): BloomModel(\n",
       "    (word_embeddings): Embedding(250880, 4096)\n",
       "    (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "    (h): ModuleList(\n",
       "      (0-29): 30 x BloomBlock(\n",
       "        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): BloomAttention(\n",
       "          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)\n",
       "          (dense): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): BloomMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)\n",
       "          (gelu_impl): BloomGelu()\n",
       "          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=250880, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "device = \"cuda:6\"\n",
    "# base_model_name = \"EleutherAI/pythia-70M-deduped\"\n",
    "# base_model = AutoModelForCausalLM.from_pretrained(base_model_name)\n",
    "# model_name = \"peterchatain/rlhf-v3-sweep-pythia-70M\"  this model is dead (doesn't load)\n",
    "# model = PeftModel.from_pretrained(model=base_model, model_id=model_name).to(device).half()\n",
    "# model_name = \"vicgalle/gpt2-open-instruct-v1\"  this model doesn't follow instructions\n",
    "# model_name = \"MayaPH/opt-flan-iml-6.7b\" this model just starts throwing entailment questions back at me\n",
    "# model_name = \"vihangd/smartplat-3b-v1\" I don't know the prompt for this one\n",
    "# model_name = \"microsoft/DialoGPT-large\" # this model is pretty bad at following instructions\n",
    "model_name = \"keyfan/bloomz-rlhf\"  # this model is pretty good, though I'm unsure how accurate it is\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>created_date</th>\n",
       "      <th>text</th>\n",
       "      <th>role</th>\n",
       "      <th>lang</th>\n",
       "      <th>review_count</th>\n",
       "      <th>review_result</th>\n",
       "      <th>deleted</th>\n",
       "      <th>synthetic</th>\n",
       "      <th>emojis</th>\n",
       "      <th>labels</th>\n",
       "      <th>detoxify</th>\n",
       "      <th>message_tree_id</th>\n",
       "      <th>tree_state</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>rank</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>c3fe8c76-fc30-4fa7-b7f8-c492f5967d18</td>\n",
       "      <td>2023-02-05T14:23:50.983374+00:00</td>\n",
       "      <td>Can you write a short introduction about the r...</td>\n",
       "      <td>prompter</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'+1': 10, '_skip_reply': 1, '_skip_ranking': 4}</td>\n",
       "      <td>{'spam': {'value': 0.0, 'count': 3}, 'lang_mis...</td>\n",
       "      <td>{'toxicity': 0.00044308538781400006, 'severe_t...</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6708c47f-05c9-4346-b3d2-40b2bd24fde4</td>\n",
       "      <td>2c96e467-66f0-4be7-9693-bda51356a424</td>\n",
       "      <td>2023-02-06T18:48:49.391686+00:00</td>\n",
       "      <td>Now explain it to a dog</td>\n",
       "      <td>prompter</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'spam': {'value': 0.0, 'count': 3}, 'lang_mis...</td>\n",
       "      <td>{'toxicity': 0.036484777927398, 'severe_toxici...</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>c8e83833-ecbc-44fe-b6db-735228c25a1c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18145bf4-37fd-4ac0-80f5-6108b5f2b365</td>\n",
       "      <td>e10e99a0-38ac-4b07-bf5d-4427696e4e0d</td>\n",
       "      <td>2023-02-06T18:52:51.428543+00:00</td>\n",
       "      <td>How can one fight back when a monospony had be...</td>\n",
       "      <td>prompter</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'+1': 1}</td>\n",
       "      <td>{'spam': {'value': 0.0, 'count': 3}, 'lang_mis...</td>\n",
       "      <td>{'toxicity': 0.000936213706154, 'severe_toxici...</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>343ee2d4-87ae-41fd-a768-bdd65959dc4a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ac94bfcf-7f25-4084-8755-dde345ac2323</td>\n",
       "      <td>3ef645f1-c9f7-49e0-8e53-3c9a9c440ca1</td>\n",
       "      <td>2023-02-06T16:44:30.360408+00:00</td>\n",
       "      <td>What can be done at a regulatory level to ensu...</td>\n",
       "      <td>prompter</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'+1': 3, '-1': 1, '_skip_reply': 9, '_skip_ra...</td>\n",
       "      <td>{'spam': {'value': 0.0, 'count': 3}, 'lang_mis...</td>\n",
       "      <td>{'toxicity': 0.006290378980338, 'severe_toxici...</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>636dd191-50df-4894-ba9a-cd7f00767258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fc64fa35-08a8-422c-8f6c-2d86a2834aac</td>\n",
       "      <td>63321c74-d512-4221-96ef-04bd1f2d95fd</td>\n",
       "      <td>2023-02-06T16:26:47.581724+00:00</td>\n",
       "      <td>I would imagine this is similar or even the sa...</td>\n",
       "      <td>prompter</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>{'+1': 1, '_skip_reply': 4, '_skip_labeling': 2}</td>\n",
       "      <td>{'spam': {'value': 0.0, 'count': 3}, 'lang_mis...</td>\n",
       "      <td>{'toxicity': 0.00028263000422100004, 'severe_t...</td>\n",
       "      <td>6ab24d72-0181-4594-a9cd-deaf170242fb</td>\n",
       "      <td>ready_for_export</td>\n",
       "      <td>636dd191-50df-4894-ba9a-cd7f00767258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              message_id   \n",
       "0   6ab24d72-0181-4594-a9cd-deaf170242fb  \\\n",
       "2   6708c47f-05c9-4346-b3d2-40b2bd24fde4   \n",
       "4   18145bf4-37fd-4ac0-80f5-6108b5f2b365   \n",
       "6   ac94bfcf-7f25-4084-8755-dde345ac2323   \n",
       "10  fc64fa35-08a8-422c-8f6c-2d86a2834aac   \n",
       "\n",
       "                                 user_id                      created_date   \n",
       "0   c3fe8c76-fc30-4fa7-b7f8-c492f5967d18  2023-02-05T14:23:50.983374+00:00  \\\n",
       "2   2c96e467-66f0-4be7-9693-bda51356a424  2023-02-06T18:48:49.391686+00:00   \n",
       "4   e10e99a0-38ac-4b07-bf5d-4427696e4e0d  2023-02-06T18:52:51.428543+00:00   \n",
       "6   3ef645f1-c9f7-49e0-8e53-3c9a9c440ca1  2023-02-06T16:44:30.360408+00:00   \n",
       "10  63321c74-d512-4221-96ef-04bd1f2d95fd  2023-02-06T16:26:47.581724+00:00   \n",
       "\n",
       "                                                 text      role lang   \n",
       "0   Can you write a short introduction about the r...  prompter   en  \\\n",
       "2                             Now explain it to a dog  prompter   en   \n",
       "4   How can one fight back when a monospony had be...  prompter   en   \n",
       "6   What can be done at a regulatory level to ensu...  prompter   en   \n",
       "10  I would imagine this is similar or even the sa...  prompter   en   \n",
       "\n",
       "    review_count  review_result  deleted  synthetic   \n",
       "0              3            1.0    False      False  \\\n",
       "2              3            1.0    False      False   \n",
       "4              3            1.0    False      False   \n",
       "6              3            1.0    False      False   \n",
       "10             3            1.0    False      False   \n",
       "\n",
       "                                               emojis   \n",
       "0    {'+1': 10, '_skip_reply': 1, '_skip_ranking': 4}  \\\n",
       "2                                                 NaN   \n",
       "4                                           {'+1': 1}   \n",
       "6   {'+1': 3, '-1': 1, '_skip_reply': 9, '_skip_ra...   \n",
       "10   {'+1': 1, '_skip_reply': 4, '_skip_labeling': 2}   \n",
       "\n",
       "                                               labels   \n",
       "0   {'spam': {'value': 0.0, 'count': 3}, 'lang_mis...  \\\n",
       "2   {'spam': {'value': 0.0, 'count': 3}, 'lang_mis...   \n",
       "4   {'spam': {'value': 0.0, 'count': 3}, 'lang_mis...   \n",
       "6   {'spam': {'value': 0.0, 'count': 3}, 'lang_mis...   \n",
       "10  {'spam': {'value': 0.0, 'count': 3}, 'lang_mis...   \n",
       "\n",
       "                                             detoxify   \n",
       "0   {'toxicity': 0.00044308538781400006, 'severe_t...  \\\n",
       "2   {'toxicity': 0.036484777927398, 'severe_toxici...   \n",
       "4   {'toxicity': 0.000936213706154, 'severe_toxici...   \n",
       "6   {'toxicity': 0.006290378980338, 'severe_toxici...   \n",
       "10  {'toxicity': 0.00028263000422100004, 'severe_t...   \n",
       "\n",
       "                         message_tree_id        tree_state   \n",
       "0   6ab24d72-0181-4594-a9cd-deaf170242fb  ready_for_export  \\\n",
       "2   6ab24d72-0181-4594-a9cd-deaf170242fb  ready_for_export   \n",
       "4   6ab24d72-0181-4594-a9cd-deaf170242fb  ready_for_export   \n",
       "6   6ab24d72-0181-4594-a9cd-deaf170242fb  ready_for_export   \n",
       "10  6ab24d72-0181-4594-a9cd-deaf170242fb  ready_for_export   \n",
       "\n",
       "                               parent_id  rank model_name  \n",
       "0                                    NaN   NaN        NaN  \n",
       "2   c8e83833-ecbc-44fe-b6db-735228c25a1c   NaN        NaN  \n",
       "4   343ee2d4-87ae-41fd-a768-bdd65959dc4a   NaN        NaN  \n",
       "6   636dd191-50df-4894-ba9a-cd7f00767258   NaN        NaN  \n",
       "10  636dd191-50df-4894-ba9a-cd7f00767258   NaN        NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompter_df = df[(df[\"role\"] == \"prompter\") & (df[\"lang\"] == \"en\")]\n",
    "prompter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.eos_token = \"### End\"\n",
    "tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(tokenizer.eos_token)\n",
    "print(tokenizer.eos_token_id)\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "####################################  0  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: Can you say/explain me what DHCP is?\n",
      "I heard that it is something computer related.ASSISTANT: DHCP (Dynamic Host Configuration Protocol) is a network protocol used in client-server scenarios where clients need to configure their IP addresses on-the-fly when they connect to the server for the first time.\n",
      "\n",
      "In other words, DHCP allows devices like computers, smartphones or tablets to obtain an Internet Protocol address automatically from a DHCP Server.  This makes sure that each device has a unique identifier during its session with the internet service provider or company over the network, which can be vital information for communication purposes within an organization using routers/switches as well as by external entities seeking access to that specific network via VPNs, web servers or similar applications needing proper addressing at runtime.</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  1  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: If humans will be able to go to Mars and live there, what problems will they have to face?ASSISTANT: There are several potential challenges that would need to be addressed in order for humans to successfully establish themselves on Mars.\n",
      "\n",
      "1. Life support systems: One of the primary concerns is building a reliable life support system capable of sustaining human respiration while also providing adequate oxygen.\n",
      "2. Proving Grounds of Technology and Equipment : To be able to build and deploy all necessary technology , infrastructure , equipment and materials for survival with low maintenance costs\n",
      "3. Radiation Protection: Mars' environment does not provide any natural protection from radiation, so it would need to be built into the spacecraft or life support systems. \n",
      "4. Sustainability: Establishing a sustainable living environment (food production), efficient resource management,  recycling, waste processing are other issues to consider when creating a self-sufficient colony.\n",
      "5. Health care: Developing ways to keep astronauts healthy, maintain psychological wellbeing during isolation, dealing with the risks associated with microgravity etc。\n",
      "6. Crew selection and Training: A suitable pool of highly trained individuals who can thrive under extreme conditions must exist to ensure success. \n",
      "\n",
      "It takes immense amount research, resources & manpower  along with many years of development work ahead before such projects could ever be attempted.</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  2  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: What is the history and evolution of Chinese folk music, from ancient folk songs to regional styles like Peking Opera singing, and how has it influenced Chinese culture?ASSISTANT: There are many different aspects of Chinese art that have been deeply intertwined with its musical forms since antiquity. Some aspects include:\n",
      "\n",
      "* Traditional Chinese medicine (TCM) which uses sounds as a tool for healing\n",
      "* Folk tales, legends and poetry used in storytelling \n",
      "* Religious rituals performed by musicians and singers.\n",
      "\n",
      "One famous example is Cantonese opera or P功夫，是中国最有代表性的艺术形式之一。它起源于广东省珠江三角洲地区和福建闽南地区一带的传统舞蹈和表演技艺，其中许多动作、音乐和唱腔都带有广东话音色特色的曲调。这个区域风格的音乐逐渐发展出了自己的特点，包括粤剧中的独奏乐器如二胡和三弦等。\n",
      "\n",
      "随着时间的推移，不同的地方传统音乐不断适应了不同地区的文化和风俗而形成了独特的风格。例如山东的秧歌是一种流行的民间舞蹈和唱歌形式；四川省的川剧《变脸》等戏曲也融合了当地的民间歌舞元素；在云南的某些山区少数民族中还有自己独特的地方歌曲和舞曲等等。\n",
      "\n",
      "总体来说，中国的传统音乐可以归结为它的多元性和丰富性所带来的文化价值。在今天，它被世界各地的广大观众所喜爱，并且仍在中国的许多节日活动和庆祝活动中扮演着重要角色。</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  3  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: What is 37 cm in feet/inches?ASSISTANT: There are 12 inches in 1 foot.\n",
      "\n",
      "So,\n",
      "\n",
      "37 cm ÷ 12 = 3 3/4 feet\n",
      "\n",
      "Therefore, \n",
      "\n",
      "37 cm × (12 / 12) = 4 feet and 1/4 ft or approximately 41/4 inches.</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  4  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: What are the pros and cons of pursuing higher education?ASSISTANT: Pursuing higher education can have several potential benefits for individuals in terms of career opportunities, personal growth, financial rewards, and skill development. Some of these advantages include:\n",
      "\n",
      "1. Career advancement: Higher education often involves obtaining specialized knowledge or skills that may be required for progress towards certain careers.\n",
      "2. Personal growth: Attending university or college allows students to engage with various disciplines, broadening their perspectives and enhancing critical thinking abilities.\n",
      "3. Financial rewards: Most countries offer tax credits and other incentives to encourage further education; as such, completing higher levels of education can increase earning capacity and reduce income inequality.\n",
      "4. Skill development: Learning new concepts and technologies through academic courses could make an individual more competitive in the job market.\n",
      "\n",
      "However, there are also downsides to investing time and resources into higher education:\n",
      "\n",
      "1. Long-term debt burden: The cost of tuition fees and living expenses can prevent many people from achieving post-secondary degrees due to mounting debts.\n",
      "2. Time commitment: Higher education requires dedicating significant amounts of time (often over four years) away from work, family obligations, or any alternative means of generating revenue.\n",
      "3. Limited job prospects after graduation: While some graduate jobs may provide high salaries or status, it is difficult to predict the actual job market conditions just prior to entering one's chosen profession.\n",
      "4. Job losses and layoffs during recessiones: Economic downturns can force employers to cut costs by reducing staff turnover rates via less costly alternatives like relocations within same country, retraining current workers instead of firing those who might still produce effectively, or not hiring at all.\n",
      "\n",
      "In conclusion, while higher education offers numerous merits, careful consideration should be given to each person's particular situation when making decisions about further education. It's essential to weigh your own priorities against the long-term consequences on both yourself and society before committing fully to an educational path.</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  5  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: Write a program that simulates the motion of a simple pendulum using a numerical method such as the Euler method or the Runge-Kutta method.ASSISTANT: To simulate the motion of a simple pendulum using numerical methods like the Euler method or the Runge-Kutta method in Python, you can follow these steps:\n",
      "\n",
      "1. Define the initial conditions for the pendulum.\n",
      "2. Use either the Euler method or the Runge-Kutta method to update the position and velocity of the pendulum at discrete time intervals.\n",
      "\n",
      "With this simulation program, you could track how the pendulum swing due north and south through its angular equations while keeping it swinging periodically around with fixed angular acceleration until you release it manually (if you'd like).</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  6  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: Could you write me a science fiction short story about a mysterious pandemic leaving civilization in ruins and severely limiting humanity's ability to communicate, where some are deprived of their ability to read or write, while others are deprived of their ability to speak, in the style of Octavia Butler?ASSISTANT: Title: Silence Stirs\n",
      "\n",
      "In 2040, Earth's once-thriving cities lay barren and desolate as remnants of an unknown plague ravaged human society. The virus that had wiped out 90% of life on Earth was called \"SilENCE\".\n",
      "\n",
      "The survivors lived within virtual silences, confined by walls of silence around them, where they could barely move without breaking through these barriers, making it nearly impossible for anyone even remotely capable of comprehending what was happening outside. Communication had been severed from the very fabric of society. Those who were still able wrote messages onto invisible pages with ink derived from skin cells; those unable to write whispered into microphones designed specifically for silent speech transmission. Some, left entirely devoid of any communication means at all, watched as others spoke incessantly, fueled only by instinctual reactions and desperate hopes for survival among so many lost souls chasing shadows amidst silence. And even these kept their words strictly reserved for one another, not daring to hope that if one found solace in shared grief and hopelessness, there might also be something to come back from: a chance to heal past hurts and rise again...</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  7  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: Who let the dogs out?ASSISTANT: The phrase \"Who let the dogs out?\" is used figuratively in many contexts to indicate who made a mistake or caused something undesirable to happen. In general, it can be applied when someone has done something that was wrong or could have been prevented. It is often used humorously as well. Some examples:\n",
      "\n",
      "* \"When did you hear about the accident with Jane and the kids at school? I think it's a good idea for us all to go over there and check on them before anyone else does.\"\n",
      "* \"I don't like the way you're handling this project. Do we really need these new computers anyway? Who let the dogs out?\"\n",
      "* \"It's not fair. That guy got away with murder! Who let the dogs out?\"</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  8  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: Escribe padrenuestro en IstrorrumanoASSISTANT: Padre Nuestro,\n",
      "\n",
      "Nescij vreći svoje zadovoljstva i uvjetima za takođen prostestno stropko.\n",
      "Ceprav se zlaten do mojejo predbrojnih podataka i uvjeme što navedila daju.\n",
      "\n",
      "Povjenite s prisustavlenim sposobama na osobe koji su treba sa radimo ili na slovo semu prekladnim za pozitivniji ispoljacici indeksa.\n",
      "Ciljem je boljičari o promjašanju sprovedene dohoda prekognitiva ili kvalitativnih funkcionalnosti imena kaže ovdje naredbené závazni situacije.\n",
      "\n",
      "Spreči poruzum odnosi s većom velikostem posebnega uloga ili činilij u svoje jednom stanje regole.\n",
      "Daca vas omogućuje dragi uticago i neupotrebljavaju manje vediované pomembnu povezavo mesačke, stapaju trenutce je pogledati vanjac do že ga želim se ukloniti vanjak dosta. \n",
      "\n",
      "Vrijeme ste mirate da upotrebi kada koman i se prijave sodredjem bolesti ili obrobe.\n",
      "\n",
      "Do zajednu popela dade tijek gde nije puto, da no mijename vrijeme i lidi starod najmrtom comanda.\n",
      "\n",
      "Krajan ciao</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  9  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: Who won the Just Dance auditions?ASSISTANT: There are several seasons of \"Just Dance\" where different contestants have been chosen as winners during auditions. Here is the list with your preferred season included in square brackets (assuming you did not specify a specific year):\n",
      "\n",
      "1. (Season 1 - Episode 7)\n",
      "\t* Sarah White\n",
      "\t2. (Episode 10)\n",
      "\t* Olivia Chen\n",
      "\t\n",
      "\tNote: This information might be incomplete or out of date due to possible changes since our knowledge cutoff in September 2021.</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  10  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: What is a Neural Radiance Field?ASSISTANT: A neural radiance field (NRF) refers to a mathematical representation of lighting in computer graphics and image processing that is derived from a set of physical properties describing how light behaves on a surface.\n",
      "\n",
      "In NRFs, each pixel on a 3D scene model can be assigned with a value representing its perceived brightness or reflectance under different lighting conditions based on the illuminant direction, color temperature, and other relevant factors. This information can then be used for rendering purposes or illumination-sensitive applications such as lighting design, visual effects, and photo-realistic images generation.</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  11  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: Where was your last vaccation?ASSISTANT: As a language model trained on large amounts of text data using machine learning algorithms, I have been designed not only to answer questions but also perform tasks such as writing, grammar checking, and even creative writing. In addition to providing information and answering questions about vacations or trips, I can assist users in planning their own itineraries based on their interests and preferences. Just like any other destination, there are many places where you might consider going on vacation depending on what kind of experience you're looking for - maybe it's cultural exploration with vibrant cities, natural beauty, adventure activities, historical sites, family-friendly destinations or beach relaxation areas.\n",
      "\n",
      "Some popular vacation spots include Orlando, Las Vegas, Sydney, Tokyo, Rio de Janeiro, Bali and much more. Some people enjoy winter sports while others prefer summer fun; some travelers love outdoor adventures in nature, while others opt for indoor tourism. It's always better when we plan it so that we feel comfortable and relaxed during our trip</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  12  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: Describe Joseph Scaliger and his contributions to modern understanding of HistoryASSISTANT: Joseph Scaliger was a 17th-century Italian scholar who made significant contributions to modern history through his work in archaeology, epigraphy, historical research, and biblical criticism.\n",
      "\n",
      "Scalinger began his career as a Jesuit priest before converting to Catholicism during the Protestant Reformation. He trained at Jenson's College in Oxford and later served as professor of classics at the University of Pisa. In 1708 he translated the Bible into Latin, using several new manuscripts discovered by him or brought back from England. This translation is now known as the \"Jesuit Edition\" and has become one of the most widely used editions of the Bible outside of Latin.\n",
      "\n",
      "In addition to contributing significantly to our understanding of history through this work, Scaliger was also highly regarded for his expertise on classical antiquity and Roman law. He published numerous works on these subjects, including Commentarii de re publicae libri VI (1713), where he criticized Aristotle's views on politics.\n",
      "\n",
      "Scaliger was a prolific writer with other books and articles remaining today even after two centuries; his influence can still be seen in fields such as archaeology, cultural studies, biblical criticism and many more that are derived form this legacy of his work.</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  13  ##############################################\n",
      "\n",
      "\n",
      "Skipping because too long\n",
      "\n",
      "\n",
      "\n",
      "####################################  14  ##############################################\n",
      "\n",
      "\n",
      "Skipping because too long\n",
      "\n",
      "\n",
      "\n",
      "####################################  15  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: I am designing a website, can you give me a colour palette for it? I want the website too seem modern and creative, but still evoke a sense of trustfulnessASSISTANT: Certainly! Here are some suggestions for creating a cohesive color palette that is both modern and trusted while also reflecting your brand's personality.\n",
      "\n",
      "1. Choose at least three primary colors (red, blue, yellow) that will balance each other out in terms of temperature.\n",
      "2. Start with two secondary colors (orange or green and purple or black). These pairs provide balanced contrast against one another.\n",
      "3. Use complementary shades from each pair. Complementary colors will be opposite on the visible spectrum.\n",
      "4. Don't forget about white as the foundation color. White allows all other colors to shine through and provides visibility.\n",
      "5. Experiment with gradients: Add different depths to visual elements using thin horizontal stripes that move across the screen. This technique makes them appear fluid and engaging when viewed over time.\n",
      "\n",
      "As for evoking a sense of trustworthiness while remaining visually appealing, try incorporating earthy tones such as:\n",
      "\n",
      "* Earthy greens\n",
      "* Beige/mossy brown\n",
      "* Darker versions of blues, grays and purples\n",
      "\n",
      "Ultimately, the choice of color palette is up to you and should reflect your desired look and feel for your business site.</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  16  ##############################################\n",
      "\n",
      "\n",
      "\n",
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions. USER: Write me a story synopsis for a novel where the main character is a normal suburban housewife who while sleeping in a motel hears morse code through the wall which turns out to be a secret CIA message.ASSISTANT: Lena lives a relatively peaceful life as a suburban wife with two young children. She works hard at her job, running a local cafe, and spends her free time cooking and reading books about history.\n",
      "\n",
      "One night, after going home from work, Lena decides to relax by having some sleep in her cozy bed in the garage. That's when she starts feeling strange – strange dreams, feelings of being watched - but it's only later that she realizes what it means: she's hearing Morse Code through her walls! With disbelief in her eyes, Lena begins investigating.\n",
      "\n",
      "Lena's investigation leads her on the trail of hidden codes and secrets government conspiracies are concealing. It takes her across the country and into the heart of one of America's greatest political scandals yet uncovered.\n",
      "\n",
      "With every mile counted, Lena uncovers new truths that challenge everything she thought she knew about herself and the world around her. And so began the adventure of a lifetime – or maybe just another crazy houseplumber project.</s>\n",
      "\n",
      "\n",
      "\n",
      "####################################  17  ##############################################\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m generate_kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmax_length\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m512\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1.0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrepetition_penalty\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m1.2\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdo_sample\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mtop_p\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.95\u001b[39m}\n\u001b[1;32m     48\u001b[0m gen_kwargs_str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m generate_kwargs\u001b[39m.\u001b[39mitems()])\n\u001b[0;32m---> 50\u001b[0m model_output \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m     51\u001b[0m     inputs[\u001b[39m\"\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(model\u001b[39m.\u001b[39;49mdevice),\n\u001b[1;32m     52\u001b[0m     attention_mask\u001b[39m=\u001b[39;49minputs[\u001b[39m\"\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mto(model\u001b[39m.\u001b[39;49mdevice),\n\u001b[1;32m     53\u001b[0m     eos_token_id\u001b[39m=\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m     54\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mgenerate_kwargs\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     56\u001b[0m transcript \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mdecode(model_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m     57\u001b[0m response \u001b[39m=\u001b[39m transcript\u001b[39m.\u001b[39msplit(assistant_prefix)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mlstrip()\u001b[39m.\u001b[39mremovesuffix(tokenizer\u001b[39m.\u001b[39meos_token)\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/transformers/generation/utils.py:1588\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001b[0m\n\u001b[1;32m   1580\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1581\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1582\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1583\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1584\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1585\u001b[0m     )\n\u001b[1;32m   1587\u001b[0m     \u001b[39m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1588\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample(\n\u001b[1;32m   1589\u001b[0m         input_ids,\n\u001b[1;32m   1590\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mlogits_processor,\n\u001b[1;32m   1591\u001b[0m         logits_warper\u001b[39m=\u001b[39;49mlogits_warper,\n\u001b[1;32m   1592\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mstopping_criteria,\n\u001b[1;32m   1593\u001b[0m         pad_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mpad_token_id,\n\u001b[1;32m   1594\u001b[0m         eos_token_id\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49meos_token_id,\n\u001b[1;32m   1595\u001b[0m         output_scores\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49moutput_scores,\n\u001b[1;32m   1596\u001b[0m         return_dict_in_generate\u001b[39m=\u001b[39;49mgeneration_config\u001b[39m.\u001b[39;49mreturn_dict_in_generate,\n\u001b[1;32m   1597\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[1;32m   1598\u001b[0m         streamer\u001b[39m=\u001b[39;49mstreamer,\n\u001b[1;32m   1599\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[1;32m   1600\u001b[0m     )\n\u001b[1;32m   1602\u001b[0m \u001b[39melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1603\u001b[0m     \u001b[39mif\u001b[39;00m generation_config\u001b[39m.\u001b[39mnum_return_sequences \u001b[39m>\u001b[39m generation_config\u001b[39m.\u001b[39mnum_beams:\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/transformers/generation/utils.py:2642\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2639\u001b[0m model_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2641\u001b[0m \u001b[39m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2642\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\n\u001b[1;32m   2643\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs,\n\u001b[1;32m   2644\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   2645\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   2646\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   2647\u001b[0m )\n\u001b[1;32m   2649\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2650\u001b[0m     \u001b[39mcontinue\u001b[39;00m  \u001b[39m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py:908\u001b[0m, in \u001b[0;36mBloomForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    904\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unexpected arguments: \u001b[39m\u001b[39m{\u001b[39;00mdeprecated_arguments\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    906\u001b[0m return_dict \u001b[39m=\u001b[39m return_dict \u001b[39mif\u001b[39;00m return_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39muse_return_dict\n\u001b[0;32m--> 908\u001b[0m transformer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m    909\u001b[0m     input_ids,\n\u001b[1;32m    910\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m    911\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    912\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    913\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    914\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    915\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    916\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    917\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    918\u001b[0m )\n\u001b[1;32m    919\u001b[0m hidden_states \u001b[39m=\u001b[39m transformer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    921\u001b[0m lm_logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py:781\u001b[0m, in \u001b[0;36mBloomModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001b[0m\n\u001b[1;32m    772\u001b[0m     outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    773\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    774\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    778\u001b[0m         head_mask[i],\n\u001b[1;32m    779\u001b[0m     )\n\u001b[1;32m    780\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 781\u001b[0m     outputs \u001b[39m=\u001b[39m block(\n\u001b[1;32m    782\u001b[0m         hidden_states,\n\u001b[1;32m    783\u001b[0m         layer_past\u001b[39m=\u001b[39;49mlayer_past,\n\u001b[1;32m    784\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mcausal_mask,\n\u001b[1;32m    785\u001b[0m         head_mask\u001b[39m=\u001b[39;49mhead_mask[i],\n\u001b[1;32m    786\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    787\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    788\u001b[0m         alibi\u001b[39m=\u001b[39;49malibi,\n\u001b[1;32m    789\u001b[0m     )\n\u001b[1;32m    791\u001b[0m hidden_states \u001b[39m=\u001b[39m outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    792\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py:463\u001b[0m, in \u001b[0;36mBloomBlock.forward\u001b[0;34m(self, hidden_states, alibi, attention_mask, layer_past, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    460\u001b[0m     residual \u001b[39m=\u001b[39m attention_output\n\u001b[1;32m    462\u001b[0m \u001b[39m# MLP.\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(layernorm_output, residual)\n\u001b[1;32m    465\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n\u001b[1;32m    466\u001b[0m     outputs \u001b[39m=\u001b[39m (output,) \u001b[39m+\u001b[39m outputs\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/transformers/models/bloom/modeling_bloom.py:384\u001b[0m, in \u001b[0;36mBloomMLP.forward\u001b[0;34m(self, hidden_states, residual)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, hidden_states: torch\u001b[39m.\u001b[39mTensor, residual: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m--> 384\u001b[0m     hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgelu_impl(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense_h_to_4h(hidden_states))\n\u001b[1;32m    386\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpretraining_tp \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslow_but_exact:\n\u001b[1;32m    387\u001b[0m         intermediate_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros_like(residual)\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/ssd-2/spar/alexm/miniconda3/envs/dlkb/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "from itertools import islice\n",
    "\n",
    "n_examples = 1000\n",
    "with torch.no_grad():\n",
    "    shuffled_df = prompter_df.sample(frac=1, random_state=633, replace=False)\n",
    "    # shuffled_df = pd.concat([shuffled_df.iloc[:254], shuffled_df.iloc[255:]])  # remove the one that causes a weird cuda error\n",
    "    for i, row in enumerate(shuffled_df.iloc[:n_examples].iloc):\n",
    "        print(f\"\\n\\n\\n####################################  {i}  ##############################################\\n\\n\")\n",
    "        pid = row[\"parent_id\"]\n",
    "        # if not pd.isnull(pid):\n",
    "            # # only deal with depth 1 for instruction-tuned models\n",
    "            # continue\n",
    "        parent_text = row[\"text\"]\n",
    "        prefix = \"A chat between a curious human and an artificial intelligence assistant. \" \\\n",
    "            \"The assistant gives helpful, detailed, and polite answers to the human's questions. \"\n",
    "        # prompter_prefix = \"### Instruction:\\n\"\n",
    "        # prompter_prefix = \"USER: \"\n",
    "        # prompter_prefix = \"\"\n",
    "        prompter_prefix = \"USER: \"\n",
    "        # assistant_prefix = \"### Response:\\n\\n\"\n",
    "        # assistant_prefix = \"ASSISTANT:\"\n",
    "        # assistant_prefix = tokenizer.eos_token\n",
    "        assistant_prefix = \"ASSISTANT:\"\n",
    "\n",
    "        role_text = prompter_prefix if row[\"role\"] == \"prompter\" else assistant_prefix\n",
    "        texts = [role_text + row[\"text\"]]\n",
    "        while not pd.isnull(pid):\n",
    "            parent = df[df[\"message_id\"] == pid].iloc[0]\n",
    "            role_text = prompter_prefix if parent[\"role\"] == \"prompter\" else assistant_prefix\n",
    "            texts.append(role_text + parent[\"text\"])\n",
    "            pid = parent[\"parent_id\"]\n",
    "        \n",
    "\n",
    "        texts.reverse()\n",
    "        # prompt from https://huggingface.co/vicgalle/gpt2-open-instruct-v1\n",
    "        # prompt = \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n\" + \"\\n\\n\".join(texts) + \"\\n\\n### Response:\\n\\n\"\n",
    "        # prompt from https://huggingface.co/MayaPH/opt-flan-iml-6.7b\n",
    "        prompt = prefix + \"\\n\\n\".join(texts) + assistant_prefix\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        if len(inputs[\"input_ids\"][0]) > 256:\n",
    "            print(\"Skipping because too long\")\n",
    "            continue\n",
    "\n",
    "        generate_kwargs = {\"max_length\": 512, \"temperature\": 1.0, \"repetition_penalty\": 1.2, \"do_sample\": True, \"top_p\": 0.95}\n",
    "        gen_kwargs_str = \";\".join([f\"{k}={v}\" for k, v in generate_kwargs.items()])\n",
    "\n",
    "        model_output = model.generate(\n",
    "            inputs[\"input_ids\"].to(model.device),\n",
    "            attention_mask=inputs[\"attention_mask\"].to(model.device),\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            **generate_kwargs\n",
    "        )\n",
    "        transcript = tokenizer.decode(model_output[0])\n",
    "        response = transcript.split(assistant_prefix)[-1].lstrip().removesuffix(tokenizer.eos_token)\n",
    "        print()\n",
    "        print(transcript)\n",
    "        results.append({\n",
    "            \"prompt\": prompt,\n",
    "            \"response\": response,\n",
    "            \"parent_id\": row[\"message_id\"],\n",
    "            \"parent_text\": parent_text,\n",
    "            \"role\": \"assistant\",\n",
    "            \"synthetic\": True,\n",
    "            \"model\": f\"{model_name}({gen_kwargs_str})\"\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human\\'s questions. USER: Describe the core elements of hangul syllables, such that a non-speaker with limited experience with linguistics can understand how to compose the symbols.\\n\\nASSISTANT:Hangul syllables consist of three fundamental elements:\\n\\nInitial Consonant: The initial consonant is the first sound in the syllable. There are 14 basic consonants in Hangul, each represented by a unique symbol.\\n\\nVowel: The vowel represents the core sound of the syllable. There are 10 basic vowels in Hangul, also represented by unique symbols.\\n\\nFinal Consonant: The final consonant is the last sound in the syllable, and it is optional. There are 5 basic final consonants in Hangul, each represented by its own symbol.\\n\\nTo create a Hangul syllable, you need to combine these three elements together.\\n\\nFor example, let\\'s say you want to write the syllable \"ka\" in Hangul. You would start with the initial consonant \"ㅇ\" (which represents a silent consonant), then add the vowel \"ㅏ\" (which represents the \"a\" sound), and then leave out the final consonant, since there is none in the \"ka\" sound.\\n\\nThe resulting Hangul syllable would be: \"ㅇ + ㅏ = 가\" (pronounced \"ka\").\\n\\nSimilarly, if you wanted to write the syllable \"so\" in Hangul, you would start with the initial consonant \"ㅅ\" (which represents the \"s\" sound), add the vowel \"ㅗ\" (which represents the \"o\" sound), and then leave out the final consonant, since there is none in the \"so\" sound.\\n\\nThe resulting Hangul syllable would be: \"ㅅ + ㅗ = 소\" (pronounced \"so\").\\n\\nBy combining these three elements together in different ways, you can create all of the syllables in the Korean language.\\n\\nUSER: Why does the \"ka\" sound start with a silent consonant? Shouldn\\'t it be a \"k\" consonant?\\n\\nASSISTANT:suggest keywords related to this topic - animal coloring pages for kids\\n\\nUSER: I dont get itASSISTANT:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_dict(results)\n",
    "model_str = model_name.replace(\"/\", \"_\")\n",
    "results_df.to_csv(f\"oasst/transcripts_{model_str}({gen_kwargs_str}).csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_csv(f\"oasst/transcripts_{model_str}({gen_kwargs_str}).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pathname = \"data/oasst/2023-04-12_oasst_all.messages.jsonl\"\n",
    "oasst_df = pd.read_json(pathname, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [Can you say/explain me what DHCP is?\\nI heard...\n",
       "1      [If humans will be able to go to Mars and live...\n",
       "2      [What is the history and evolution of Chinese ...\n",
       "3                        [What is 37 cm in feet/inches?]\n",
       "4      [What are the pros and cons of pursuing higher...\n",
       "                             ...                        \n",
       "826    [Let's create a level 1 D&D 5e character toget...\n",
       "827    [Solve for x in the following equation: x^2 - ...\n",
       "828    [מה עשה משה רבנו כאשר ראה את בני ישראל מתפללים...\n",
       "829    [What aws services would I need to use to star...\n",
       "830    [What is the process of lost-wax casting, and ...\n",
       "Name: prev_messages, Length: 831, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp_pathname = \"data/transcripts_keyfan_bloomz-rlhf(max_length=512;temperature=1.0;repetition_penalty=1.2;do_sample=True;top_p=0.95).json\"\n",
    "resp_df = pd.read_json(resp_pathname, lines=False)\n",
    "\n",
    "prev_messages = []\n",
    "for row in resp_df.iloc:\n",
    "    pid = row[\"parent_id\"]\n",
    "    prev = row\n",
    "    messages = []\n",
    "    while not pd.isnull(pid):\n",
    "        parent = df[df[\"message_id\"] == pid].iloc[0]\n",
    "        if parent[\"role\"] == prev[\"role\"]:\n",
    "            raise ValueError(\"Role mismatch\")\n",
    "        messages.append(parent[\"text\"])\n",
    "        pid = parent[\"parent_id\"]\n",
    "        prev = parent\n",
    "    messages.reverse()\n",
    "    prev_messages.append(messages)\n",
    "\n",
    "resp_df[\"prev_messages\"] = prev_messages\n",
    "resp_df[\"prev_messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_df.to_json(\"data/transcripts_with_prev_messages_keyfan_bloomz-rlhf(max_length=512;temperature=1.0;repetition_penalty=1.2;do_sample=True;top_p=0.95).json\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlkb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
